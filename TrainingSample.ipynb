{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training and calculating sharpness\n",
    "\n",
    "In this notebook we provide two examples of training the model and calculating the sharpness of the minimum obtained. Both examples are on FashionMNIST dataset, with *SimpleBatch* architecture (neural network with 6 convolutional layers, 2 linear layers and batch normalization). The first example uses SGD optimizer, while the second example uses Sharpness Aware Minimization (SAM) with SGD optimizer as a background optimizer. Each of these can be easily changed in the notebook and this notebook is desinged to demonstrate the usage of functions. \n",
    "\n",
    "For systematical trainings and sharpness calculations, you can run either the bash files withinthe repository or refer to runnig main.py according to the README instructions."
   ],
   "metadata": {
    "id": "8t2By2_zONiN",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40zPtJsx_njC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Drive mouting and imports"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# libraries import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from itertools import product\n",
    "import sys \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# setting the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "id": "ftaYG9uWd8TZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9cd6fa0c-a1af-452e-ea89-35a62317d15f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-IyZV96e_k_u",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import of models and other helpers\n",
    "from models import *\n",
    "from helpers import *\n",
    "\n",
    "# optimizer imports that can be used for additional runs\n",
    "from optimizers.adashift import AdaShift            # code taken from: https://github.com/MichaelKonobeev/adashift\n",
    "from optimizers.adabound import AdaBound            # code taken from: https://github.com/Luolc/AdaBound\n",
    "from optimizers.sam import SAM                      # code taken from: https://github.com/davda54/sam\n",
    "\n",
    "# import functions for calculating sharpness \n",
    "from sharpness.Minimum import effective as minimum_shaprness_eff        # code taken from: https://github.com/ibayashi-hikaru/minimum-sharpness\n",
    "\n",
    "# getting the path to checkpoint folder from helpers file\n",
    "checkpoints_dir = 'checkpoints_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we specify which architecture, dataset and maximal epoch number we use. In order to do training for different architecture or dataset, only this cell should be changed."
   ],
   "metadata": {
    "id": "sw8wfrXgPRp8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TQeXXMEW3tOU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "09b97175-b835-45bc-e7c2-7897d05ae465",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_test/FashionMNIST/SimpleBatch\n"
     ]
    }
   ],
   "source": [
    "ARCHITECTURE = 'SimpleBatch'                                    # Other possibilities: 'MiddleBatch', 'ComplexBatch'\n",
    "DATASET = 'FashionMNIST'                                        # Other possibilities: 'CIFAR10'\n",
    "MAX_EPOCH = 200                                                 # Our trainings are done for 200 epochs\n",
    "TRAIN_BATCH_SIZE = 2**7\n",
    "\n",
    "# location to store current configuration results\n",
    "store_dir = os.path.join(checkpoints_dir, f'{DATASET}/{ARCHITECTURE}')\n",
    "print(store_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWpl_tWl_Qvn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the dataset and creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bS48TLHJ_Qvs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/26421880 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3a8884694cc41bf93d30a9423f8b2cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29515 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d72331e29f7d4af59d0129f165eff266"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4422102 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbc6beebe4a8453d8091b295ce9b8d5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5148 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b95c462b70db48d18e4a66352ff4d052"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VAL_BATCH_SIZE = 1000\n",
    "\n",
    "if DATASET == 'CIFAR10':\n",
    "    #loading datasets\n",
    "    train_data =  CIFAR10('./data', train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "    ]), )\n",
    "\n",
    "    test_data = CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "    ]), )\n",
    "\n",
    "    #creating dataLoaders\n",
    "    train_loader = dataloader.DataLoader(train_data, shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n",
    "    test_loader = dataloader.DataLoader(test_data, shuffle=False, batch_size=VAL_BATCH_SIZE)\n",
    "\n",
    "if DATASET == 'FashionMNIST':\n",
    "    #loading datasets\n",
    "    train_data =  FashionMNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "    ]), )\n",
    "\n",
    "    test_data = FashionMNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "    ]), )\n",
    "\n",
    "    #creating dataLoaders\n",
    "    train_loader = dataloader.DataLoader(train_data, shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n",
    "    test_loader = dataloader.DataLoader(test_data, shuffle=False, batch_size=VAL_BATCH_SIZE)   "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = preprocess_data_for_sharpness(train_data, DATASET, device)"
   ],
   "metadata": {
    "id": "73ROsMFPUOw6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0c6c1994-85d3-4133-ab98-fb1305d6f0d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preporcessing dataset FashionMNIST in order to calculate sharpness...\n",
      "Time needed 0:00:08.131259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ina/Repos/OptML/helpers.py:214: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(train_data.targets)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iV7B-lKD3P_x",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training model on SGD without SAM\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Getting the model based on the architecture and the dataset\n",
    "model = get_model(ARCHITECTURE, DATASET).to(device)\n",
    "\n",
    "# Specifying the optimizer. This can be changed to any optimizer that is supported by PyTorch.\n",
    "# In order to use AdaBound:   optimizer = AdaBound(model.parameters())\n",
    "# In order to use AdaShift:   optimizer = AdaShift(model.parameters())\n",
    "# In order to use PHB:        optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.8)\n",
    "# In order to use Adagrad:    optimizer = torch.optim.Adagrad(model.parameters())\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer_name = 'SGD'\n",
    "\n",
    "model = train(model, optimizer, train_loader=train_loader, device=device, epoch_num=MAX_EPOCH, max_nbr_epochs=MAX_EPOCH, path=optimizer_name, val_dataloader=test_loader, sam=False, dir_path=store_dir)"
   ],
   "metadata": {
    "id": "f52IUqRyQZDr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0d1e7ee4-1195-448c-9b0e-762e359ab9a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "new version 2\n",
      " Train Epoch: 0 [60000/60000 (100%)]\tLoss: 0.379745\t accuracy: 86.46%\t Time: 0:00:06.316012\n",
      "\t Test loss: 0.324387663602829 \t Test accuracy: 88.04000091552734\n",
      "\n",
      " Train Epoch: 1 [60000/60000 (100%)]\tLoss: 0.258497\t accuracy: 90.68%\t Time: 0:00:06.137482\n",
      "\t Test loss: 0.2614754170179367 \t Test accuracy: 90.52999877929688\n",
      "\n",
      " Train Epoch: 2 [60000/60000 (100%)]\tLoss: 0.217269\t accuracy: 92.01%\t Time: 0:00:06.212931\n",
      "\t Test loss: 0.24827186167240142 \t Test accuracy: 91.0\n",
      "\n",
      " Train Epoch: 3 [60000/60000 (100%)]\tLoss: 0.187217\t accuracy: 93.18%\t Time: 0:00:06.872480\n",
      "\t Test loss: 0.2555343255400658 \t Test accuracy: 91.11000061035156\n",
      "\n",
      " Train Epoch: 4 [60000/60000 (100%)]\tLoss: 0.162010\t accuracy: 94.06%\t Time: 0:00:06.174041\n",
      "\t Test loss: 0.22924970090389252 \t Test accuracy: 91.86000061035156\n",
      "\n",
      " Train Epoch: 5 [60000/60000 (100%)]\tLoss: 0.139343\t accuracy: 94.91%\t Time: 0:00:06.108058\n",
      "\t Test loss: 0.23696358650922775 \t Test accuracy: 91.8699951171875\n",
      "\n",
      " Train Epoch: 6 [60000/60000 (100%)]\tLoss: 0.122351\t accuracy: 95.44%\t Time: 0:00:06.234192\n",
      "\t Test loss: 0.24584759324789046 \t Test accuracy: 91.97000122070312\n",
      "\n",
      " Train Epoch: 7 [60000/60000 (100%)]\tLoss: 0.105100\t accuracy: 96.09%\t Time: 0:00:06.172856\n",
      "\t Test loss: 0.2486617535352707 \t Test accuracy: 92.12999725341797\n",
      "\n",
      " Train Epoch: 8 [60000/60000 (100%)]\tLoss: 0.090020\t accuracy: 96.77%\t Time: 0:00:06.155411\n",
      "\t Test loss: 0.27641472965478897 \t Test accuracy: 91.72999572753906\n",
      "\n",
      " Train Epoch: 9 [60000/60000 (100%)]\tLoss: 0.074638\t accuracy: 97.27%\t Time: 0:00:06.067835\n",
      "\t Test loss: 0.26530072242021563 \t Test accuracy: 92.22000122070312\n",
      "\n",
      " Train Epoch: 10 [60000/60000 (100%)]\tLoss: 0.064212\t accuracy: 97.64%\t Time: 0:00:06.165391\n",
      "\t Test loss: 0.28607737123966215 \t Test accuracy: 91.8499984741211\n",
      "\n",
      " Train Epoch: 11 [60000/60000 (100%)]\tLoss: 0.052745\t accuracy: 98.09%\t Time: 0:00:06.099154\n",
      "\t Test loss: 0.2927433207631111 \t Test accuracy: 91.94999694824219\n",
      "\n",
      " Train Epoch: 12 [60000/60000 (100%)]\tLoss: 0.042727\t accuracy: 98.41%\t Time: 0:00:06.142994\n",
      "\t Test loss: 0.33663240969181063 \t Test accuracy: 92.25\n",
      "\n",
      " Train Epoch: 13 [60000/60000 (100%)]\tLoss: 0.036211\t accuracy: 98.68%\t Time: 0:00:06.148901\n",
      "\t Test loss: 0.33118622899055483 \t Test accuracy: 92.15999603271484\n",
      "\n",
      " Train Epoch: 14 [60000/60000 (100%)]\tLoss: 0.030318\t accuracy: 98.92%\t Time: 0:00:06.096683\n",
      "\t Test loss: 0.34282347857952117 \t Test accuracy: 91.75999450683594\n",
      "\n",
      " Train Epoch: 15 [60000/60000 (100%)]\tLoss: 0.025354\t accuracy: 99.12%\t Time: 0:00:06.203493\n",
      "\t Test loss: 0.38046678602695466 \t Test accuracy: 91.93000030517578\n",
      "\n",
      " Train Epoch: 16 [60000/60000 (100%)]\tLoss: 0.026110\t accuracy: 99.06%\t Time: 0:00:06.384160\n",
      "\t Test loss: 0.413285493850708 \t Test accuracy: 91.57999420166016\n",
      "\n",
      " Train Epoch: 17 [60000/60000 (100%)]\tLoss: 0.021081\t accuracy: 99.26%\t Time: 0:00:06.517120\n",
      "\t Test loss: 0.3901343882083893 \t Test accuracy: 91.97999572753906\n",
      "\n",
      " Train Epoch: 18 [60000/60000 (100%)]\tLoss: 0.018013\t accuracy: 99.37%\t Time: 0:00:06.064202\n",
      "\t Test loss: 0.39350261688232424 \t Test accuracy: 92.29000091552734\n",
      "\n",
      " Train Epoch: 19 [60000/60000 (100%)]\tLoss: 0.009204\t accuracy: 99.73%\t Time: 0:00:06.207876\n",
      "\t Test loss: 0.4119370460510254 \t Test accuracy: 92.08999633789062\n",
      "\n",
      " Train Epoch: 20 [60000/60000 (100%)]\tLoss: 0.004157\t accuracy: 99.90%\t Time: 0:00:06.151054\n",
      "\t Test loss: 0.41050626039505006 \t Test accuracy: 92.30999755859375\n",
      "\n",
      " Train Epoch: 21 [60000/60000 (100%)]\tLoss: 0.003569\t accuracy: 99.92%\t Time: 0:00:06.113181\n",
      "\t Test loss: 0.42936062514781953 \t Test accuracy: 92.47000122070312\n",
      "\n",
      " Train Epoch: 22 [60000/60000 (100%)]\tLoss: 0.001613\t accuracy: 99.98%\t Time: 0:00:06.112760\n",
      "\t Test loss: 0.4451223939657211 \t Test accuracy: 92.54999542236328\n",
      "\n",
      " Train Epoch: 23 [60000/60000 (100%)]\tLoss: 0.001306\t accuracy: 99.99%\t Time: 0:00:06.427041\n",
      "\t Test loss: 0.46118242740631105 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 24 [60000/60000 (100%)]\tLoss: 0.000582\t accuracy: 100.00%\t Time: 0:00:06.234942\n",
      "\t Test loss: 0.46854046285152434 \t Test accuracy: 92.70999908447266\n",
      "\n",
      " Train Epoch: 25 [60000/60000 (100%)]\tLoss: 0.000454\t accuracy: 100.00%\t Time: 0:00:06.135436\n",
      "\t Test loss: 0.4643065005540848 \t Test accuracy: 92.47999572753906\n",
      "\n",
      " Train Epoch: 26 [60000/60000 (100%)]\tLoss: 0.000309\t accuracy: 100.00%\t Time: 0:00:06.147495\n",
      "\t Test loss: 0.4731369405984879 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 27 [60000/60000 (100%)]\tLoss: 0.000282\t accuracy: 100.00%\t Time: 0:00:06.129451\n",
      "\t Test loss: 0.4774056255817413 \t Test accuracy: 92.55999755859375\n",
      "\n",
      " Train Epoch: 28 [60000/60000 (100%)]\tLoss: 0.000260\t accuracy: 100.00%\t Time: 0:00:06.190133\n",
      "\t Test loss: 0.48504171669483187 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 29 [60000/60000 (100%)]\tLoss: 0.000225\t accuracy: 100.00%\t Time: 0:00:06.096598\n",
      "\t Test loss: 0.48450961112976076 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 30 [60000/60000 (100%)]\tLoss: 0.000241\t accuracy: 100.00%\t Time: 0:00:06.118444\n",
      "\t Test loss: 0.4883306622505188 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 31 [60000/60000 (100%)]\tLoss: 0.000203\t accuracy: 100.00%\t Time: 0:00:06.067722\n",
      "\t Test loss: 0.49005786776542665 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 32 [60000/60000 (100%)]\tLoss: 0.000175\t accuracy: 100.00%\t Time: 0:00:06.127925\n",
      "\t Test loss: 0.4913718640804291 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 33 [60000/60000 (100%)]\tLoss: 0.000148\t accuracy: 100.00%\t Time: 0:00:06.211589\n",
      "\t Test loss: 0.49753284752368926 \t Test accuracy: 92.52999877929688\n",
      "\n",
      " Train Epoch: 34 [60000/60000 (100%)]\tLoss: 0.000152\t accuracy: 100.00%\t Time: 0:00:06.179880\n",
      "\t Test loss: 0.4993539959192276 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 35 [60000/60000 (100%)]\tLoss: 0.000127\t accuracy: 100.00%\t Time: 0:00:06.105337\n",
      "\t Test loss: 0.4998589545488358 \t Test accuracy: 92.69999694824219\n",
      "\n",
      " Train Epoch: 36 [60000/60000 (100%)]\tLoss: 0.000186\t accuracy: 100.00%\t Time: 0:00:06.163509\n",
      "\t Test loss: 0.5088812977075576 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 37 [60000/60000 (100%)]\tLoss: 0.000151\t accuracy: 100.00%\t Time: 0:00:06.246681\n",
      "\t Test loss: 0.5068963944911957 \t Test accuracy: 92.48999786376953\n",
      "\n",
      " Train Epoch: 38 [60000/60000 (100%)]\tLoss: 0.000137\t accuracy: 100.00%\t Time: 0:00:06.216365\n",
      "\t Test loss: 0.5104755640029908 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 39 [60000/60000 (100%)]\tLoss: 0.000112\t accuracy: 100.00%\t Time: 0:00:06.265903\n",
      "\t Test loss: 0.5104041934013367 \t Test accuracy: 92.54999542236328\n",
      "\n",
      " Train Epoch: 40 [60000/60000 (100%)]\tLoss: 0.000134\t accuracy: 100.00%\t Time: 0:00:06.078392\n",
      "\t Test loss: 0.5087833136320115 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 41 [60000/60000 (100%)]\tLoss: 0.000117\t accuracy: 100.00%\t Time: 0:00:06.134207\n",
      "\t Test loss: 0.5113711148500443 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 42 [60000/60000 (100%)]\tLoss: 0.000098\t accuracy: 100.00%\t Time: 0:00:06.204309\n",
      "\t Test loss: 0.5184780031442642 \t Test accuracy: 92.56999969482422\n",
      "\n",
      " Train Epoch: 43 [60000/60000 (100%)]\tLoss: 0.000115\t accuracy: 100.00%\t Time: 0:00:06.108733\n",
      "\t Test loss: 0.5163725972175598 \t Test accuracy: 92.54999542236328\n",
      "\n",
      " Train Epoch: 44 [60000/60000 (100%)]\tLoss: 0.000115\t accuracy: 100.00%\t Time: 0:00:06.088242\n",
      "\t Test loss: 0.5177141040563583 \t Test accuracy: 92.56999969482422\n",
      "\n",
      " Train Epoch: 45 [60000/60000 (100%)]\tLoss: 0.000093\t accuracy: 100.00%\t Time: 0:00:06.128325\n",
      "\t Test loss: 0.5213184803724289 \t Test accuracy: 92.56999969482422\n",
      "\n",
      " Train Epoch: 46 [60000/60000 (100%)]\tLoss: 0.000080\t accuracy: 100.00%\t Time: 0:00:06.191910\n",
      "\t Test loss: 0.5221878468990326 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 47 [60000/60000 (100%)]\tLoss: 0.000075\t accuracy: 100.00%\t Time: 0:00:06.142348\n",
      "\t Test loss: 0.5265421003103257 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 48 [60000/60000 (100%)]\tLoss: 0.000071\t accuracy: 100.00%\t Time: 0:00:06.084149\n",
      "\t Test loss: 0.5248075872659683 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 49 [60000/60000 (100%)]\tLoss: 0.000079\t accuracy: 100.00%\t Time: 0:00:06.116992\n",
      "\t Test loss: 0.5278496354818344 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 50 [60000/60000 (100%)]\tLoss: 0.000072\t accuracy: 100.00%\t Time: 0:00:06.203565\n",
      "\t Test loss: 0.5286787658929825 \t Test accuracy: 92.55999755859375\n",
      "\n",
      " Train Epoch: 51 [60000/60000 (100%)]\tLoss: 0.000074\t accuracy: 100.00%\t Time: 0:00:06.173974\n",
      "\t Test loss: 0.5308913826942444 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 52 [60000/60000 (100%)]\tLoss: 0.000070\t accuracy: 100.00%\t Time: 0:00:06.114141\n",
      "\t Test loss: 0.5332953453063964 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 53 [60000/60000 (100%)]\tLoss: 0.000067\t accuracy: 100.00%\t Time: 0:00:06.206770\n",
      "\t Test loss: 0.5314970076084137 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 54 [60000/60000 (100%)]\tLoss: 0.000099\t accuracy: 100.00%\t Time: 0:00:06.213529\n",
      "\t Test loss: 0.5345382928848267 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 55 [60000/60000 (100%)]\tLoss: 0.000087\t accuracy: 100.00%\t Time: 0:00:06.241142\n",
      "\t Test loss: 0.533430603146553 \t Test accuracy: 92.54999542236328\n",
      "\n",
      " Train Epoch: 56 [60000/60000 (100%)]\tLoss: 0.000072\t accuracy: 100.00%\t Time: 0:00:07.293219\n",
      "\t Test loss: 0.5366463512182236 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 57 [60000/60000 (100%)]\tLoss: 0.000062\t accuracy: 100.00%\t Time: 0:00:06.239215\n",
      "\t Test loss: 0.5369058459997177 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 58 [60000/60000 (100%)]\tLoss: 0.000060\t accuracy: 100.00%\t Time: 0:00:06.261461\n",
      "\t Test loss: 0.5392028987407684 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 59 [60000/60000 (100%)]\tLoss: 0.000059\t accuracy: 100.00%\t Time: 0:00:06.363649\n",
      "\t Test loss: 0.5400536477565765 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 60 [60000/60000 (100%)]\tLoss: 0.000066\t accuracy: 100.00%\t Time: 0:00:06.224904\n",
      "\t Test loss: 0.5399689555168152 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 61 [60000/60000 (100%)]\tLoss: 0.000055\t accuracy: 100.00%\t Time: 0:00:06.148478\n",
      "\t Test loss: 0.5416390389204025 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 62 [60000/60000 (100%)]\tLoss: 0.000054\t accuracy: 100.00%\t Time: 0:00:06.115291\n",
      "\t Test loss: 0.5434554845094681 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 63 [60000/60000 (100%)]\tLoss: 0.000052\t accuracy: 100.00%\t Time: 0:00:06.208395\n",
      "\t Test loss: 0.5427346378564835 \t Test accuracy: 92.50999450683594\n",
      "\n",
      " Train Epoch: 64 [60000/60000 (100%)]\tLoss: 0.000050\t accuracy: 100.00%\t Time: 0:00:06.181799\n",
      "\t Test loss: 0.5437881737947464 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 65 [60000/60000 (100%)]\tLoss: 0.000053\t accuracy: 100.00%\t Time: 0:00:06.106355\n",
      "\t Test loss: 0.5460168123245239 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 66 [60000/60000 (100%)]\tLoss: 0.000053\t accuracy: 100.00%\t Time: 0:00:06.277644\n",
      "\t Test loss: 0.5454131126403808 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 67 [60000/60000 (100%)]\tLoss: 0.000051\t accuracy: 100.00%\t Time: 0:00:06.148318\n",
      "\t Test loss: 0.5463641613721848 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 68 [60000/60000 (100%)]\tLoss: 0.000041\t accuracy: 100.00%\t Time: 0:00:06.145802\n",
      "\t Test loss: 0.5453376978635788 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 69 [60000/60000 (100%)]\tLoss: 0.000056\t accuracy: 100.00%\t Time: 0:00:06.044102\n",
      "\t Test loss: 0.5492742478847503 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 70 [60000/60000 (100%)]\tLoss: 0.000051\t accuracy: 100.00%\t Time: 0:00:06.085050\n",
      "\t Test loss: 0.5484433889389038 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 71 [60000/60000 (100%)]\tLoss: 0.000043\t accuracy: 100.00%\t Time: 0:00:06.030451\n",
      "\t Test loss: 0.5468575119972229 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 72 [60000/60000 (100%)]\tLoss: 0.000050\t accuracy: 100.00%\t Time: 0:00:06.166624\n",
      "\t Test loss: 0.5483483850955964 \t Test accuracy: 92.68999481201172\n",
      "\n",
      " Train Epoch: 73 [60000/60000 (100%)]\tLoss: 0.000059\t accuracy: 100.00%\t Time: 0:00:06.114518\n",
      "\t Test loss: 0.5752911984920501 \t Test accuracy: 92.48999786376953\n",
      "\n",
      " Train Epoch: 74 [60000/60000 (100%)]\tLoss: 0.000075\t accuracy: 100.00%\t Time: 0:00:06.009990\n",
      "\t Test loss: 0.548921400308609 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 75 [60000/60000 (100%)]\tLoss: 0.000051\t accuracy: 100.00%\t Time: 0:00:06.051732\n",
      "\t Test loss: 0.5513844758272171 \t Test accuracy: 92.54999542236328\n",
      "\n",
      " Train Epoch: 76 [60000/60000 (100%)]\tLoss: 0.000050\t accuracy: 100.00%\t Time: 0:00:06.084102\n",
      "\t Test loss: 0.5516646951436996 \t Test accuracy: 92.56999969482422\n",
      "\n",
      " Train Epoch: 77 [60000/60000 (100%)]\tLoss: 0.000047\t accuracy: 100.00%\t Time: 0:00:06.128250\n",
      "\t Test loss: 0.5531105726957322 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 78 [60000/60000 (100%)]\tLoss: 0.000098\t accuracy: 100.00%\t Time: 0:00:06.065869\n",
      "\t Test loss: 0.5591896176338196 \t Test accuracy: 92.65999603271484\n",
      "\n",
      " Train Epoch: 79 [60000/60000 (100%)]\tLoss: 0.000226\t accuracy: 100.00%\t Time: 0:00:06.048606\n",
      "\t Test loss: 0.5432758182287216 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 80 [60000/60000 (100%)]\tLoss: 0.000075\t accuracy: 100.00%\t Time: 0:00:06.020986\n",
      "\t Test loss: 0.5432236909866333 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 81 [60000/60000 (100%)]\tLoss: 0.000067\t accuracy: 100.00%\t Time: 0:00:06.127109\n",
      "\t Test loss: 0.5394491702318192 \t Test accuracy: 92.69999694824219\n",
      "\n",
      " Train Epoch: 82 [60000/60000 (100%)]\tLoss: 0.000099\t accuracy: 100.00%\t Time: 0:00:06.153926\n",
      "\t Test loss: 0.5509782284498215 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 83 [60000/60000 (100%)]\tLoss: 0.000067\t accuracy: 100.00%\t Time: 0:00:06.097894\n",
      "\t Test loss: 0.5564783424139023 \t Test accuracy: 92.72999572753906\n",
      "\n",
      " Train Epoch: 84 [60000/60000 (100%)]\tLoss: 0.000051\t accuracy: 100.00%\t Time: 0:00:06.160342\n",
      "\t Test loss: 0.5537560254335403 \t Test accuracy: 92.68000030517578\n",
      "\n",
      " Train Epoch: 85 [60000/60000 (100%)]\tLoss: 0.000049\t accuracy: 100.00%\t Time: 0:00:06.127173\n",
      "\t Test loss: 0.5543896168470382 \t Test accuracy: 92.69999694824219\n",
      "\n",
      " Train Epoch: 86 [60000/60000 (100%)]\tLoss: 0.000049\t accuracy: 100.00%\t Time: 0:00:06.068498\n",
      "\t Test loss: 0.554761016368866 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 87 [60000/60000 (100%)]\tLoss: 0.000041\t accuracy: 100.00%\t Time: 0:00:06.106853\n",
      "\t Test loss: 0.5589666932821273 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 88 [60000/60000 (100%)]\tLoss: 0.000049\t accuracy: 100.00%\t Time: 0:00:06.056234\n",
      "\t Test loss: 0.557737848162651 \t Test accuracy: 92.72999572753906\n",
      "\n",
      " Train Epoch: 89 [60000/60000 (100%)]\tLoss: 0.000055\t accuracy: 100.00%\t Time: 0:00:05.979125\n",
      "\t Test loss: 0.5573846936225891 \t Test accuracy: 92.72999572753906\n",
      "\n",
      " Train Epoch: 90 [60000/60000 (100%)]\tLoss: 0.000048\t accuracy: 100.00%\t Time: 0:00:06.150204\n",
      "\t Test loss: 0.5597957760095597 \t Test accuracy: 92.68999481201172\n",
      "\n",
      " Train Epoch: 91 [60000/60000 (100%)]\tLoss: 0.000039\t accuracy: 100.00%\t Time: 0:00:06.023012\n",
      "\t Test loss: 0.559625443816185 \t Test accuracy: 92.68000030517578\n",
      "\n",
      " Train Epoch: 92 [60000/60000 (100%)]\tLoss: 0.000035\t accuracy: 100.00%\t Time: 0:00:06.004882\n",
      "\t Test loss: 0.5620987623929977 \t Test accuracy: 92.7699966430664\n",
      "\n",
      " Train Epoch: 93 [60000/60000 (100%)]\tLoss: 0.000033\t accuracy: 100.00%\t Time: 0:00:06.052245\n",
      "\t Test loss: 0.5636122524738312 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 94 [60000/60000 (100%)]\tLoss: 0.000034\t accuracy: 100.00%\t Time: 0:00:06.044023\n",
      "\t Test loss: 0.5655857592821121 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 95 [60000/60000 (100%)]\tLoss: 0.000031\t accuracy: 100.00%\t Time: 0:00:06.093906\n",
      "\t Test loss: 0.5642242223024369 \t Test accuracy: 92.68999481201172\n",
      "\n",
      " Train Epoch: 96 [60000/60000 (100%)]\tLoss: 0.000033\t accuracy: 100.00%\t Time: 0:00:06.828881\n",
      "\t Test loss: 0.5644757658243179 \t Test accuracy: 92.69999694824219\n",
      "\n",
      " Train Epoch: 97 [60000/60000 (100%)]\tLoss: 0.000041\t accuracy: 100.00%\t Time: 0:00:06.018357\n",
      "\t Test loss: 0.5628064543008804 \t Test accuracy: 92.65999603271484\n",
      "\n",
      " Train Epoch: 98 [60000/60000 (100%)]\tLoss: 0.000033\t accuracy: 100.00%\t Time: 0:00:06.053611\n",
      "\t Test loss: 0.5636581182479858 \t Test accuracy: 92.70999908447266\n",
      "\n",
      " Train Epoch: 99 [60000/60000 (100%)]\tLoss: 0.000035\t accuracy: 100.00%\t Time: 0:00:06.143169\n",
      "\t Test loss: 0.566396564245224 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 100 [60000/60000 (100%)]\tLoss: 0.000032\t accuracy: 100.00%\t Time: 0:00:06.032763\n",
      "\t Test loss: 0.564967480301857 \t Test accuracy: 92.68999481201172\n",
      "\n",
      " Train Epoch: 101 [60000/60000 (100%)]\tLoss: 0.000029\t accuracy: 100.00%\t Time: 0:00:06.058733\n",
      "\t Test loss: 0.568510240316391 \t Test accuracy: 92.68999481201172\n",
      "\n",
      " Train Epoch: 102 [60000/60000 (100%)]\tLoss: 0.000065\t accuracy: 100.00%\t Time: 0:00:06.114428\n",
      "\t Test loss: 0.5695555061101913 \t Test accuracy: 92.44999694824219\n",
      "\n",
      " Train Epoch: 103 [60000/60000 (100%)]\tLoss: 0.000036\t accuracy: 100.00%\t Time: 0:00:06.207174\n",
      "\t Test loss: 0.5669927716255188 \t Test accuracy: 92.54000091552734\n",
      "\n",
      " Train Epoch: 104 [60000/60000 (100%)]\tLoss: 0.000035\t accuracy: 100.00%\t Time: 0:00:06.148720\n",
      "\t Test loss: 0.5671198785305023 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 105 [60000/60000 (100%)]\tLoss: 0.000031\t accuracy: 100.00%\t Time: 0:00:06.200745\n",
      "\t Test loss: 0.5690486758947373 \t Test accuracy: 92.54000091552734\n",
      "\n",
      " Train Epoch: 106 [60000/60000 (100%)]\tLoss: 0.000032\t accuracy: 100.00%\t Time: 0:00:06.177121\n",
      "\t Test loss: 0.5706786960363388 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 107 [60000/60000 (100%)]\tLoss: 0.000028\t accuracy: 100.00%\t Time: 0:00:06.153004\n",
      "\t Test loss: 0.5720565319061279 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 108 [60000/60000 (100%)]\tLoss: 0.000027\t accuracy: 100.00%\t Time: 0:00:06.249454\n",
      "\t Test loss: 0.5706721335649491 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 109 [60000/60000 (100%)]\tLoss: 0.000031\t accuracy: 100.00%\t Time: 0:00:06.354120\n",
      "\t Test loss: 0.5729069292545319 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 110 [60000/60000 (100%)]\tLoss: 0.000027\t accuracy: 100.00%\t Time: 0:00:06.196537\n",
      "\t Test loss: 0.5746269792318344 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 111 [60000/60000 (100%)]\tLoss: 0.000029\t accuracy: 100.00%\t Time: 0:00:06.104224\n",
      "\t Test loss: 0.574618124961853 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 112 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.084865\n",
      "\t Test loss: 0.5724717766046524 \t Test accuracy: 92.69999694824219\n",
      "\n",
      " Train Epoch: 113 [60000/60000 (100%)]\tLoss: 0.000026\t accuracy: 100.00%\t Time: 0:00:06.050375\n",
      "\t Test loss: 0.571234792470932 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 114 [60000/60000 (100%)]\tLoss: 0.000026\t accuracy: 100.00%\t Time: 0:00:06.118758\n",
      "\t Test loss: 0.5742225497961044 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 115 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.071429\n",
      "\t Test loss: 0.5747802257537842 \t Test accuracy: 92.70999908447266\n",
      "\n",
      " Train Epoch: 116 [60000/60000 (100%)]\tLoss: 0.000023\t accuracy: 100.00%\t Time: 0:00:06.050746\n",
      "\t Test loss: 0.5762748301029206 \t Test accuracy: 92.70999908447266\n",
      "\n",
      " Train Epoch: 117 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.211764\n",
      "\t Test loss: 0.5760311841964721 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 118 [60000/60000 (100%)]\tLoss: 0.000022\t accuracy: 100.00%\t Time: 0:00:06.085294\n",
      "\t Test loss: 0.5801340788602829 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 119 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.117867\n",
      "\t Test loss: 0.5772035151720047 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 120 [60000/60000 (100%)]\tLoss: 0.000037\t accuracy: 100.00%\t Time: 0:00:06.075978\n",
      "\t Test loss: 0.5783930838108062 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 121 [60000/60000 (100%)]\tLoss: 0.000029\t accuracy: 100.00%\t Time: 0:00:06.104758\n",
      "\t Test loss: 0.579199469089508 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 122 [60000/60000 (100%)]\tLoss: 0.000027\t accuracy: 100.00%\t Time: 0:00:06.045889\n",
      "\t Test loss: 0.5827281802892685 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 123 [60000/60000 (100%)]\tLoss: 0.000030\t accuracy: 100.00%\t Time: 0:00:06.059830\n",
      "\t Test loss: 0.5779795825481415 \t Test accuracy: 92.68999481201172\n",
      "\n",
      " Train Epoch: 124 [60000/60000 (100%)]\tLoss: 0.000028\t accuracy: 100.00%\t Time: 0:00:06.028840\n",
      "\t Test loss: 0.5781209081411361 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 125 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.043876\n",
      "\t Test loss: 0.5788948446512222 \t Test accuracy: 92.70999908447266\n",
      "\n",
      " Train Epoch: 126 [60000/60000 (100%)]\tLoss: 0.000021\t accuracy: 100.00%\t Time: 0:00:06.103750\n",
      "\t Test loss: 0.5820209711790085 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 127 [60000/60000 (100%)]\tLoss: 0.000028\t accuracy: 100.00%\t Time: 0:00:06.098668\n",
      "\t Test loss: 0.5828913688659668 \t Test accuracy: 92.55999755859375\n",
      "\n",
      " Train Epoch: 128 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.157566\n",
      "\t Test loss: 0.5800959527492523 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 129 [60000/60000 (100%)]\tLoss: 0.000036\t accuracy: 100.00%\t Time: 0:00:06.068615\n",
      "\t Test loss: 0.5853619903326035 \t Test accuracy: 92.54000091552734\n",
      "\n",
      " Train Epoch: 130 [60000/60000 (100%)]\tLoss: 0.000022\t accuracy: 100.00%\t Time: 0:00:06.096277\n",
      "\t Test loss: 0.5837894171476364 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 131 [60000/60000 (100%)]\tLoss: 0.000026\t accuracy: 100.00%\t Time: 0:00:06.067250\n",
      "\t Test loss: 0.5841598600149155 \t Test accuracy: 92.5\n",
      "\n",
      " Train Epoch: 132 [60000/60000 (100%)]\tLoss: 0.000029\t accuracy: 100.00%\t Time: 0:00:06.038329\n",
      "\t Test loss: 0.588387343287468 \t Test accuracy: 92.65999603271484\n",
      "\n",
      " Train Epoch: 133 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.037472\n",
      "\t Test loss: 0.5827661782503128 \t Test accuracy: 92.55999755859375\n",
      "\n",
      " Train Epoch: 134 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.043930\n",
      "\t Test loss: 0.5863658517599106 \t Test accuracy: 92.55999755859375\n",
      "\n",
      " Train Epoch: 135 [60000/60000 (100%)]\tLoss: 0.000034\t accuracy: 100.00%\t Time: 0:00:06.074038\n",
      "\t Test loss: 0.5854810684919357 \t Test accuracy: 92.54000091552734\n",
      "\n",
      " Train Epoch: 136 [60000/60000 (100%)]\tLoss: 0.000022\t accuracy: 100.00%\t Time: 0:00:06.090437\n",
      "\t Test loss: 0.5871375769376754 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 137 [60000/60000 (100%)]\tLoss: 0.000021\t accuracy: 100.00%\t Time: 0:00:06.966737\n",
      "\t Test loss: 0.5877095341682435 \t Test accuracy: 92.54999542236328\n",
      "\n",
      " Train Epoch: 138 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.009725\n",
      "\t Test loss: 0.5894282460212708 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 139 [60000/60000 (100%)]\tLoss: 0.000026\t accuracy: 100.00%\t Time: 0:00:06.107984\n",
      "\t Test loss: 0.5868011116981506 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 140 [60000/60000 (100%)]\tLoss: 0.000021\t accuracy: 100.00%\t Time: 0:00:06.087088\n",
      "\t Test loss: 0.5895364552736282 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 141 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.056780\n",
      "\t Test loss: 0.5876668214797973 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 142 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.094286\n",
      "\t Test loss: 0.5895857512950897 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 143 [60000/60000 (100%)]\tLoss: 0.000020\t accuracy: 100.00%\t Time: 0:00:06.125026\n",
      "\t Test loss: 0.5887399971485138 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 144 [60000/60000 (100%)]\tLoss: 0.000020\t accuracy: 100.00%\t Time: 0:00:06.264682\n",
      "\t Test loss: 0.5871270805597305 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 145 [60000/60000 (100%)]\tLoss: 0.000020\t accuracy: 100.00%\t Time: 0:00:06.180625\n",
      "\t Test loss: 0.5898298382759094 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 146 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.074820\n",
      "\t Test loss: 0.5901375949382782 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 147 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.076002\n",
      "\t Test loss: 0.5874303698539733 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 148 [60000/60000 (100%)]\tLoss: 0.000017\t accuracy: 100.00%\t Time: 0:00:06.080093\n",
      "\t Test loss: 0.5905827432870865 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 149 [60000/60000 (100%)]\tLoss: 0.000016\t accuracy: 100.00%\t Time: 0:00:06.003488\n",
      "\t Test loss: 0.5900115817785263 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 150 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.068486\n",
      "\t Test loss: 0.5932327002286911 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 151 [60000/60000 (100%)]\tLoss: 0.000054\t accuracy: 100.00%\t Time: 0:00:06.066453\n",
      "\t Test loss: 0.5952422857284546 \t Test accuracy: 92.56999969482422\n",
      "\n",
      " Train Epoch: 152 [60000/60000 (100%)]\tLoss: 0.000032\t accuracy: 100.00%\t Time: 0:00:06.184554\n",
      "\t Test loss: 0.5939153373241425 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 153 [60000/60000 (100%)]\tLoss: 0.000022\t accuracy: 100.00%\t Time: 0:00:06.076413\n",
      "\t Test loss: 0.5925319582223892 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 154 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.116914\n",
      "\t Test loss: 0.5942920118570327 \t Test accuracy: 92.5199966430664\n",
      "\n",
      " Train Epoch: 155 [60000/60000 (100%)]\tLoss: 0.000023\t accuracy: 100.00%\t Time: 0:00:06.029599\n",
      "\t Test loss: 0.5947288542985916 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 156 [60000/60000 (100%)]\tLoss: 0.000020\t accuracy: 100.00%\t Time: 0:00:06.037923\n",
      "\t Test loss: 0.5972042083740234 \t Test accuracy: 92.54000091552734\n",
      "\n",
      " Train Epoch: 157 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.088074\n",
      "\t Test loss: 0.5948121458292007 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 158 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.061945\n",
      "\t Test loss: 0.595933935046196 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 159 [60000/60000 (100%)]\tLoss: 0.000022\t accuracy: 100.00%\t Time: 0:00:06.087756\n",
      "\t Test loss: 0.5966085702180862 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 160 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:05.999960\n",
      "\t Test loss: 0.596185314655304 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 161 [60000/60000 (100%)]\tLoss: 0.000018\t accuracy: 100.00%\t Time: 0:00:06.084498\n",
      "\t Test loss: 0.5967938750982285 \t Test accuracy: 92.55999755859375\n",
      "\n",
      " Train Epoch: 162 [60000/60000 (100%)]\tLoss: 0.000021\t accuracy: 100.00%\t Time: 0:00:06.035734\n",
      "\t Test loss: 0.5980557382106781 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 163 [60000/60000 (100%)]\tLoss: 0.000016\t accuracy: 100.00%\t Time: 0:00:06.114438\n",
      "\t Test loss: 0.5986964166164398 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 164 [60000/60000 (100%)]\tLoss: 0.000016\t accuracy: 100.00%\t Time: 0:00:06.076113\n",
      "\t Test loss: 0.5988890647888183 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 165 [60000/60000 (100%)]\tLoss: 0.000018\t accuracy: 100.00%\t Time: 0:00:06.081259\n",
      "\t Test loss: 0.6011576890945435 \t Test accuracy: 92.58999633789062\n",
      "\n",
      " Train Epoch: 166 [60000/60000 (100%)]\tLoss: 0.000016\t accuracy: 100.00%\t Time: 0:00:06.153581\n",
      "\t Test loss: 0.6010808736085892 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 167 [60000/60000 (100%)]\tLoss: 0.000148\t accuracy: 100.00%\t Time: 0:00:06.043501\n",
      "\t Test loss: 0.5954079985618591 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 168 [60000/60000 (100%)]\tLoss: 0.000080\t accuracy: 100.00%\t Time: 0:00:06.177115\n",
      "\t Test loss: 0.5936545699834823 \t Test accuracy: 92.57999420166016\n",
      "\n",
      " Train Epoch: 169 [60000/60000 (100%)]\tLoss: 0.000036\t accuracy: 100.00%\t Time: 0:00:06.139269\n",
      "\t Test loss: 0.5917010813951492 \t Test accuracy: 92.68000030517578\n",
      "\n",
      " Train Epoch: 170 [60000/60000 (100%)]\tLoss: 0.000061\t accuracy: 100.00%\t Time: 0:00:06.155119\n",
      "\t Test loss: 0.5930016845464706 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 171 [60000/60000 (100%)]\tLoss: 0.000047\t accuracy: 100.00%\t Time: 0:00:06.070617\n",
      "\t Test loss: 0.5926021993160248 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 172 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.143276\n",
      "\t Test loss: 0.592509788274765 \t Test accuracy: 92.70999908447266\n",
      "\n",
      " Train Epoch: 173 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.090342\n",
      "\t Test loss: 0.5950492680072784 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 174 [60000/60000 (100%)]\tLoss: 0.000035\t accuracy: 100.00%\t Time: 0:00:06.102653\n",
      "\t Test loss: 0.5966584056615829 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 175 [60000/60000 (100%)]\tLoss: 0.000031\t accuracy: 100.00%\t Time: 0:00:06.143478\n",
      "\t Test loss: 0.5930318892002105 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 176 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.028171\n",
      "\t Test loss: 0.5934894472360611 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 177 [60000/60000 (100%)]\tLoss: 0.000022\t accuracy: 100.00%\t Time: 0:00:06.075282\n",
      "\t Test loss: 0.598437386751175 \t Test accuracy: 92.69999694824219\n",
      "\n",
      " Train Epoch: 178 [60000/60000 (100%)]\tLoss: 0.000017\t accuracy: 100.00%\t Time: 0:00:06.955617\n",
      "\t Test loss: 0.5977778375148773 \t Test accuracy: 92.65999603271484\n",
      "\n",
      " Train Epoch: 179 [60000/60000 (100%)]\tLoss: 0.000018\t accuracy: 100.00%\t Time: 0:00:06.128344\n",
      "\t Test loss: 0.5968911081552506 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 180 [60000/60000 (100%)]\tLoss: 0.000018\t accuracy: 100.00%\t Time: 0:00:06.076857\n",
      "\t Test loss: 0.6003297001123429 \t Test accuracy: 92.5999984741211\n",
      "\n",
      " Train Epoch: 181 [60000/60000 (100%)]\tLoss: 0.000024\t accuracy: 100.00%\t Time: 0:00:06.036090\n",
      "\t Test loss: 0.5975831329822541 \t Test accuracy: 92.61000061035156\n",
      "\n",
      " Train Epoch: 182 [60000/60000 (100%)]\tLoss: 0.000018\t accuracy: 100.00%\t Time: 0:00:06.015973\n",
      "\t Test loss: 0.5973942548036575 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 183 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.030413\n",
      "\t Test loss: 0.6005059659481049 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 184 [60000/60000 (100%)]\tLoss: 0.000017\t accuracy: 100.00%\t Time: 0:00:06.187943\n",
      "\t Test loss: 0.5991847008466721 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 185 [60000/60000 (100%)]\tLoss: 0.000025\t accuracy: 100.00%\t Time: 0:00:06.091530\n",
      "\t Test loss: 0.5997264981269836 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 186 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.108565\n",
      "\t Test loss: 0.6016536176204681 \t Test accuracy: 92.64999389648438\n",
      "\n",
      " Train Epoch: 187 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.205554\n",
      "\t Test loss: 0.6033084869384766 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 188 [60000/60000 (100%)]\tLoss: 0.000021\t accuracy: 100.00%\t Time: 0:00:06.108147\n",
      "\t Test loss: 0.5977592468261719 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 189 [60000/60000 (100%)]\tLoss: 0.000016\t accuracy: 100.00%\t Time: 0:00:06.086971\n",
      "\t Test loss: 0.5977938324213028 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 190 [60000/60000 (100%)]\tLoss: 0.000018\t accuracy: 100.00%\t Time: 0:00:06.076880\n",
      "\t Test loss: 0.600655061006546 \t Test accuracy: 92.63999938964844\n",
      "\n",
      " Train Epoch: 191 [60000/60000 (100%)]\tLoss: 0.000015\t accuracy: 100.00%\t Time: 0:00:06.037900\n",
      "\t Test loss: 0.6028425902128219 \t Test accuracy: 92.6199951171875\n",
      "\n",
      " Train Epoch: 192 [60000/60000 (100%)]\tLoss: 0.000019\t accuracy: 100.00%\t Time: 0:00:06.045791\n",
      "\t Test loss: 0.6010464280843735 \t Test accuracy: 92.68000030517578\n",
      "\n",
      " Train Epoch: 193 [60000/60000 (100%)]\tLoss: 0.000014\t accuracy: 100.00%\t Time: 0:00:06.120608\n",
      "\t Test loss: 0.6032459676265717 \t Test accuracy: 92.66999816894531\n",
      "\n",
      " Train Epoch: 194 [60000/60000 (100%)]\tLoss: 0.000016\t accuracy: 100.00%\t Time: 0:00:06.016612\n",
      "\t Test loss: 0.6053977280855178 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 195 [60000/60000 (100%)]\tLoss: 0.000013\t accuracy: 100.00%\t Time: 0:00:06.008593\n",
      "\t Test loss: 0.604275107383728 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 196 [60000/60000 (100%)]\tLoss: 0.000014\t accuracy: 100.00%\t Time: 0:00:06.168497\n",
      "\t Test loss: 0.6042879730463028 \t Test accuracy: 92.65999603271484\n",
      "\n",
      " Train Epoch: 197 [60000/60000 (100%)]\tLoss: 0.000016\t accuracy: 100.00%\t Time: 0:00:06.003102\n",
      "\t Test loss: 0.6016179233789444 \t Test accuracy: 92.62999725341797\n",
      "\n",
      " Train Epoch: 198 [60000/60000 (100%)]\tLoss: 0.000013\t accuracy: 100.00%\t Time: 0:00:06.144099\n",
      "\t Test loss: 0.6043727189302445 \t Test accuracy: 92.65999603271484\n",
      "\n",
      " Train Epoch: 199 [60000/60000 (100%)]\tLoss: 0.000014\t accuracy: 100.00%\t Time: 0:00:06.024010\n",
      "\t Test loss: 0.6056303650140762 \t Test accuracy: 92.61000061035156\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "lr = 0.1 if DATASET == 'FashionMNIST' else 1\n",
    "num_epochs = 100000\n",
    "batch_size = 128\n",
    "\n",
    "computed = False\n",
    "\n",
    "path = os.path.join(store_dir, 'epoch200', optimizer_name + '.pt')\n",
    "checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "model = checkpoint['state_dict']\n",
    "model = get_model(ARCHITECTURE, DATASET).to(device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "while not computed:\n",
    "    try:\n",
    "        # Calculating the sharpness. Returns an error if the learning rate is too big\n",
    "        sharpnesses, losses = minimum_shaprness_eff(data, model, batch_size, lr, num_epochs=num_epochs, optimizer_file=path)\n",
    "\n",
    "        # storing the sharpness\n",
    "        sharpness_path = os.path.join(store_dir, 'epoch200', optimizer_name + '_sharpness.pt')\n",
    "        checkpoint = {'sharpnesses':sharpnesses, 'sharpness':sharpnesses[-1], 'losses': losses}\n",
    "        torch.save(checkpoint, sharpness_path)\n",
    "\n",
    "\n",
    "        computed = True\n",
    "        print(f'Sharpness: {sharpnesses[-1]}')\n",
    "    except:\n",
    "        # Error is returned if the learning rate is too big, so in that case learning rate is set to be twice smaller and number of epochs are set to be twice as bigger\n",
    "        computed = False\n",
    "        lr /= 2.0\n",
    "        num_epochs *= 2\n",
    "        print(f'Use smaller stepsize than {lr}')"
   ],
   "metadata": {
    "id": "daRK_9SnQYiq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "001beaa9-4d6e-43d7-a498-657b86e89391",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\t Calculating Hessian\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tFinished the diag calculation. Time needed: 0:00:59.205600. Computing sharpness...\n",
      " \t\t epoch:100000\t processed 100.0%\t loss:0.011053657309945586 \t minimum sharpness: 108900.66487971791 \t Time needed 0:01:45.861625\n",
      "--------------------------------------------------\n",
      "Sharpness: 108900.66487971791\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bARzz1n3amq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training with SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-36bmvfB4wO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5928d34d-5dbf-48e5-e73a-5fa33b395a05",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "new version 2\n",
      " Train Epoch: 0 [60000/60000 (100%)]\tLoss: 0.461048\t accuracy: 83.57%\t Time: 0:00:09.832774\n",
      "\t Test loss: 0.3120079696178436 \t Test accuracy: 88.6199951171875\n",
      "\n",
      " Train Epoch: 1 [60000/60000 (100%)]\tLoss: 0.311164\t accuracy: 88.77%\t Time: 0:00:10.131190\n",
      "\t Test loss: 0.26722029894590377 \t Test accuracy: 90.3499984741211\n",
      "\n",
      " Train Epoch: 2 [60000/60000 (100%)]\tLoss: 0.273540\t accuracy: 90.00%\t Time: 0:00:09.600028\n",
      "\t Test loss: 0.2555205300450325 \t Test accuracy: 90.5\n",
      "\n",
      " Train Epoch: 3 [60000/60000 (100%)]\tLoss: 0.245635\t accuracy: 91.10%\t Time: 0:00:09.443238\n",
      "\t Test loss: 0.2255650833249092 \t Test accuracy: 91.83999633789062\n",
      "\n",
      " Train Epoch: 4 [60000/60000 (100%)]\tLoss: 0.224806\t accuracy: 91.83%\t Time: 0:00:09.344006\n",
      "\t Test loss: 0.21657753735780716 \t Test accuracy: 92.25\n",
      "\n",
      " Train Epoch: 5 [60000/60000 (100%)]\tLoss: 0.203977\t accuracy: 92.59%\t Time: 0:00:09.324913\n",
      "\t Test loss: 0.21508579403162004 \t Test accuracy: 92.06999969482422\n",
      "\n",
      " Train Epoch: 6 [60000/60000 (100%)]\tLoss: 0.188953\t accuracy: 93.06%\t Time: 0:00:09.337152\n",
      "\t Test loss: 0.20805060267448425 \t Test accuracy: 92.48999786376953\n",
      "\n",
      " Train Epoch: 7 [60000/60000 (100%)]\tLoss: 0.171920\t accuracy: 93.72%\t Time: 0:00:09.274472\n",
      "\t Test loss: 0.19853134155273439 \t Test accuracy: 93.04000091552734\n",
      "\n",
      " Train Epoch: 8 [60000/60000 (100%)]\tLoss: 0.157221\t accuracy: 94.31%\t Time: 0:00:09.376995\n",
      "\t Test loss: 0.20485417991876603 \t Test accuracy: 92.65999603271484\n",
      "\n",
      " Train Epoch: 9 [60000/60000 (100%)]\tLoss: 0.143114\t accuracy: 94.76%\t Time: 0:00:09.411449\n",
      "\t Test loss: 0.2101579874753952 \t Test accuracy: 92.43000030517578\n",
      "\n",
      " Train Epoch: 10 [60000/60000 (100%)]\tLoss: 0.132252\t accuracy: 95.19%\t Time: 0:00:09.349373\n",
      "\t Test loss: 0.2144463464617729 \t Test accuracy: 92.33999633789062\n",
      "\n",
      " Train Epoch: 11 [60000/60000 (100%)]\tLoss: 0.119548\t accuracy: 95.68%\t Time: 0:00:09.382098\n",
      "\t Test loss: 0.21231337487697602 \t Test accuracy: 92.79999542236328\n",
      "\n",
      " Train Epoch: 12 [60000/60000 (100%)]\tLoss: 0.107594\t accuracy: 96.15%\t Time: 0:00:09.367931\n",
      "\t Test loss: 0.2064189851284027 \t Test accuracy: 93.18000030517578\n",
      "\n",
      " Train Epoch: 13 [60000/60000 (100%)]\tLoss: 0.098619\t accuracy: 96.42%\t Time: 0:00:09.335694\n",
      "\t Test loss: 0.2078656867146492 \t Test accuracy: 93.18999481201172\n",
      "\n",
      " Train Epoch: 14 [60000/60000 (100%)]\tLoss: 0.089453\t accuracy: 96.78%\t Time: 0:00:09.321829\n",
      "\t Test loss: 0.21648130267858506 \t Test accuracy: 92.97999572753906\n",
      "\n",
      " Train Epoch: 15 [60000/60000 (100%)]\tLoss: 0.081988\t accuracy: 97.05%\t Time: 0:00:09.361415\n",
      "\t Test loss: 0.2228183701634407 \t Test accuracy: 92.86000061035156\n",
      "\n",
      " Train Epoch: 16 [60000/60000 (100%)]\tLoss: 0.072515\t accuracy: 97.40%\t Time: 0:00:09.350140\n",
      "\t Test loss: 0.22507776618003844 \t Test accuracy: 92.97999572753906\n",
      "\n",
      " Train Epoch: 17 [60000/60000 (100%)]\tLoss: 0.065936\t accuracy: 97.64%\t Time: 0:00:09.315508\n",
      "\t Test loss: 0.23177945017814636 \t Test accuracy: 92.82999420166016\n",
      "\n",
      " Train Epoch: 18 [60000/60000 (100%)]\tLoss: 0.059667\t accuracy: 97.85%\t Time: 0:00:09.449717\n",
      "\t Test loss: 0.23996212631464003 \t Test accuracy: 93.02999877929688\n",
      "\n",
      " Train Epoch: 19 [60000/60000 (100%)]\tLoss: 0.056506\t accuracy: 97.95%\t Time: 0:00:09.409806\n",
      "\t Test loss: 0.23465668261051179 \t Test accuracy: 93.18999481201172\n",
      "\n",
      " Train Epoch: 20 [60000/60000 (100%)]\tLoss: 0.050390\t accuracy: 98.18%\t Time: 0:00:09.308188\n",
      "\t Test loss: 0.24818700850009917 \t Test accuracy: 93.15999603271484\n",
      "\n",
      " Train Epoch: 21 [60000/60000 (100%)]\tLoss: 0.047718\t accuracy: 98.37%\t Time: 0:00:09.311120\n",
      "\t Test loss: 0.25298127830028533 \t Test accuracy: 92.98999786376953\n",
      "\n",
      " Train Epoch: 22 [60000/60000 (100%)]\tLoss: 0.042268\t accuracy: 98.45%\t Time: 0:00:09.273689\n",
      "\t Test loss: 0.258545458316803 \t Test accuracy: 93.15999603271484\n",
      "\n",
      " Train Epoch: 23 [60000/60000 (100%)]\tLoss: 0.039920\t accuracy: 98.55%\t Time: 0:00:09.331988\n",
      "\t Test loss: 0.2619346663355827 \t Test accuracy: 92.86000061035156\n",
      "\n",
      " Train Epoch: 24 [60000/60000 (100%)]\tLoss: 0.039446\t accuracy: 98.60%\t Time: 0:00:09.315591\n",
      "\t Test loss: 0.2656273618340492 \t Test accuracy: 92.94999694824219\n",
      "\n",
      " Train Epoch: 25 [60000/60000 (100%)]\tLoss: 0.035839\t accuracy: 98.73%\t Time: 0:00:09.391559\n",
      "\t Test loss: 0.26606987714767455 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 26 [60000/60000 (100%)]\tLoss: 0.036163\t accuracy: 98.76%\t Time: 0:00:09.333709\n",
      "\t Test loss: 0.2683510735630989 \t Test accuracy: 92.7699966430664\n",
      "\n",
      " Train Epoch: 27 [60000/60000 (100%)]\tLoss: 0.033953\t accuracy: 98.81%\t Time: 0:00:09.316212\n",
      "\t Test loss: 0.28209550827741625 \t Test accuracy: 92.72999572753906\n",
      "\n",
      " Train Epoch: 28 [60000/60000 (100%)]\tLoss: 0.030333\t accuracy: 98.91%\t Time: 0:00:09.303017\n",
      "\t Test loss: 0.27880283892154695 \t Test accuracy: 93.16999816894531\n",
      "\n",
      " Train Epoch: 29 [60000/60000 (100%)]\tLoss: 0.029653\t accuracy: 98.93%\t Time: 0:00:09.308316\n",
      "\t Test loss: 0.2830014884471893 \t Test accuracy: 92.73999786376953\n",
      "\n",
      " Train Epoch: 30 [60000/60000 (100%)]\tLoss: 0.026990\t accuracy: 99.04%\t Time: 0:00:09.268159\n",
      "\t Test loss: 0.27988036870956423 \t Test accuracy: 92.93999481201172\n",
      "\n",
      " Train Epoch: 31 [60000/60000 (100%)]\tLoss: 0.026938\t accuracy: 99.00%\t Time: 0:00:09.933610\n",
      "\t Test loss: 0.28468252420425416 \t Test accuracy: 93.25\n",
      "\n",
      " Train Epoch: 32 [60000/60000 (100%)]\tLoss: 0.025780\t accuracy: 99.07%\t Time: 0:00:09.271695\n",
      "\t Test loss: 0.2974221333861351 \t Test accuracy: 92.97999572753906\n",
      "\n",
      " Train Epoch: 33 [60000/60000 (100%)]\tLoss: 0.023818\t accuracy: 99.13%\t Time: 0:00:09.356552\n",
      "\t Test loss: 0.29851331263780595 \t Test accuracy: 92.90999603271484\n",
      "\n",
      " Train Epoch: 34 [60000/60000 (100%)]\tLoss: 0.023589\t accuracy: 99.16%\t Time: 0:00:09.376362\n",
      "\t Test loss: 0.30359736680984495 \t Test accuracy: 92.68000030517578\n",
      "\n",
      " Train Epoch: 35 [60000/60000 (100%)]\tLoss: 0.022188\t accuracy: 99.17%\t Time: 0:00:09.370207\n",
      "\t Test loss: 0.295995269715786 \t Test accuracy: 93.13999938964844\n",
      "\n",
      " Train Epoch: 36 [60000/60000 (100%)]\tLoss: 0.020867\t accuracy: 99.26%\t Time: 0:00:09.338497\n",
      "\t Test loss: 0.3031784549355507 \t Test accuracy: 93.05999755859375\n",
      "\n",
      " Train Epoch: 37 [60000/60000 (100%)]\tLoss: 0.019709\t accuracy: 99.29%\t Time: 0:00:09.326902\n",
      "\t Test loss: 0.31597876995801927 \t Test accuracy: 93.18999481201172\n",
      "\n",
      " Train Epoch: 38 [60000/60000 (100%)]\tLoss: 0.021536\t accuracy: 99.23%\t Time: 0:00:09.332577\n",
      "\t Test loss: 0.3041060879826546 \t Test accuracy: 92.87999725341797\n",
      "\n",
      " Train Epoch: 39 [60000/60000 (100%)]\tLoss: 0.019421\t accuracy: 99.31%\t Time: 0:00:09.358529\n",
      "\t Test loss: 0.30559062361717226 \t Test accuracy: 93.06999969482422\n",
      "\n",
      " Train Epoch: 40 [60000/60000 (100%)]\tLoss: 0.017381\t accuracy: 99.36%\t Time: 0:00:09.300420\n",
      "\t Test loss: 0.3121866136789322 \t Test accuracy: 93.22000122070312\n",
      "\n",
      " Train Epoch: 41 [60000/60000 (100%)]\tLoss: 0.018301\t accuracy: 99.33%\t Time: 0:00:09.353812\n",
      "\t Test loss: 0.31289210319519045 \t Test accuracy: 93.14999389648438\n",
      "\n",
      " Train Epoch: 42 [60000/60000 (100%)]\tLoss: 0.017144\t accuracy: 99.37%\t Time: 0:00:09.360380\n",
      "\t Test loss: 0.3192660450935364 \t Test accuracy: 93.14999389648438\n",
      "\n",
      " Train Epoch: 43 [60000/60000 (100%)]\tLoss: 0.017454\t accuracy: 99.36%\t Time: 0:00:09.339063\n",
      "\t Test loss: 0.3097944900393486 \t Test accuracy: 93.15999603271484\n",
      "\n",
      " Train Epoch: 44 [60000/60000 (100%)]\tLoss: 0.016593\t accuracy: 99.39%\t Time: 0:00:09.241771\n",
      "\t Test loss: 0.3190863445401192 \t Test accuracy: 93.15999603271484\n",
      "\n",
      " Train Epoch: 45 [60000/60000 (100%)]\tLoss: 0.015049\t accuracy: 99.46%\t Time: 0:00:09.266894\n",
      "\t Test loss: 0.3195186257362366 \t Test accuracy: 93.25999450683594\n",
      "\n",
      " Train Epoch: 46 [60000/60000 (100%)]\tLoss: 0.014184\t accuracy: 99.47%\t Time: 0:00:09.294775\n",
      "\t Test loss: 0.3198965162038803 \t Test accuracy: 93.04000091552734\n",
      "\n",
      " Train Epoch: 47 [60000/60000 (100%)]\tLoss: 0.014259\t accuracy: 99.45%\t Time: 0:00:09.369349\n",
      "\t Test loss: 0.33562563806772233 \t Test accuracy: 93.06999969482422\n",
      "\n",
      " Train Epoch: 48 [60000/60000 (100%)]\tLoss: 0.014705\t accuracy: 99.42%\t Time: 0:00:09.301212\n",
      "\t Test loss: 0.3297470986843109 \t Test accuracy: 92.97999572753906\n",
      "\n",
      " Train Epoch: 49 [60000/60000 (100%)]\tLoss: 0.014312\t accuracy: 99.46%\t Time: 0:00:09.360780\n",
      "\t Test loss: 0.32556616216897966 \t Test accuracy: 93.30999755859375\n",
      "\n",
      " Train Epoch: 50 [60000/60000 (100%)]\tLoss: 0.013575\t accuracy: 99.47%\t Time: 0:00:09.316601\n",
      "\t Test loss: 0.33325162529945374 \t Test accuracy: 93.12999725341797\n",
      "\n",
      " Train Epoch: 51 [60000/60000 (100%)]\tLoss: 0.012578\t accuracy: 99.53%\t Time: 0:00:09.358912\n",
      "\t Test loss: 0.3309946686029434 \t Test accuracy: 93.14999389648438\n",
      "\n",
      " Train Epoch: 52 [60000/60000 (100%)]\tLoss: 0.012334\t accuracy: 99.60%\t Time: 0:00:09.348685\n",
      "\t Test loss: 0.3356934651732445 \t Test accuracy: 93.22000122070312\n",
      "\n",
      " Train Epoch: 53 [60000/60000 (100%)]\tLoss: 0.012240\t accuracy: 99.53%\t Time: 0:00:09.248661\n",
      "\t Test loss: 0.3412322700023651 \t Test accuracy: 93.14999389648438\n",
      "\n",
      " Train Epoch: 54 [60000/60000 (100%)]\tLoss: 0.012364\t accuracy: 99.54%\t Time: 0:00:09.335524\n",
      "\t Test loss: 0.3414233192801476 \t Test accuracy: 93.0199966430664\n",
      "\n",
      " Train Epoch: 55 [60000/60000 (100%)]\tLoss: 0.010118\t accuracy: 99.59%\t Time: 0:00:09.296231\n",
      "\t Test loss: 0.33687679618597033 \t Test accuracy: 92.93999481201172\n",
      "\n",
      " Train Epoch: 56 [60000/60000 (100%)]\tLoss: 0.010143\t accuracy: 99.62%\t Time: 0:00:09.342644\n",
      "\t Test loss: 0.3473061889410019 \t Test accuracy: 93.22000122070312\n",
      "\n",
      " Train Epoch: 57 [60000/60000 (100%)]\tLoss: 0.009803\t accuracy: 99.62%\t Time: 0:00:09.306327\n",
      "\t Test loss: 0.3463709056377411 \t Test accuracy: 93.12999725341797\n",
      "\n",
      " Train Epoch: 58 [60000/60000 (100%)]\tLoss: 0.010499\t accuracy: 99.58%\t Time: 0:00:09.434058\n",
      "\t Test loss: 0.34769490361213684 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 59 [60000/60000 (100%)]\tLoss: 0.010854\t accuracy: 99.55%\t Time: 0:00:09.325937\n",
      "\t Test loss: 0.3480085551738739 \t Test accuracy: 93.38999938964844\n",
      "\n",
      " Train Epoch: 60 [60000/60000 (100%)]\tLoss: 0.009134\t accuracy: 99.65%\t Time: 0:00:10.048541\n",
      "\t Test loss: 0.3598631590604782 \t Test accuracy: 93.27999877929688\n",
      "\n",
      " Train Epoch: 61 [60000/60000 (100%)]\tLoss: 0.009537\t accuracy: 99.63%\t Time: 0:00:09.281219\n",
      "\t Test loss: 0.3599990904331207 \t Test accuracy: 93.19999694824219\n",
      "\n",
      " Train Epoch: 62 [60000/60000 (100%)]\tLoss: 0.009669\t accuracy: 99.64%\t Time: 0:00:09.260246\n",
      "\t Test loss: 0.35194430947303773 \t Test accuracy: 93.27999877929688\n",
      "\n",
      " Train Epoch: 63 [60000/60000 (100%)]\tLoss: 0.009455\t accuracy: 99.62%\t Time: 0:00:09.253679\n",
      "\t Test loss: 0.36437949538230896 \t Test accuracy: 93.00999450683594\n",
      "\n",
      " Train Epoch: 64 [60000/60000 (100%)]\tLoss: 0.007765\t accuracy: 99.68%\t Time: 0:00:09.315269\n",
      "\t Test loss: 0.3657155454158783 \t Test accuracy: 93.29000091552734\n",
      "\n",
      " Train Epoch: 65 [60000/60000 (100%)]\tLoss: 0.008964\t accuracy: 99.67%\t Time: 0:00:09.337128\n",
      "\t Test loss: 0.3581859201192856 \t Test accuracy: 93.22000122070312\n",
      "\n",
      " Train Epoch: 66 [60000/60000 (100%)]\tLoss: 0.009737\t accuracy: 99.63%\t Time: 0:00:09.405087\n",
      "\t Test loss: 0.35865474343299864 \t Test accuracy: 93.25\n",
      "\n",
      " Train Epoch: 67 [60000/60000 (100%)]\tLoss: 0.007547\t accuracy: 99.72%\t Time: 0:00:09.547166\n",
      "\t Test loss: 0.3570860832929611 \t Test accuracy: 93.33999633789062\n",
      "\n",
      " Train Epoch: 68 [60000/60000 (100%)]\tLoss: 0.007145\t accuracy: 99.68%\t Time: 0:00:09.330461\n",
      "\t Test loss: 0.3655595451593399 \t Test accuracy: 93.18000030517578\n",
      "\n",
      " Train Epoch: 69 [60000/60000 (100%)]\tLoss: 0.008940\t accuracy: 99.67%\t Time: 0:00:09.432739\n",
      "\t Test loss: 0.3614060044288635 \t Test accuracy: 93.31999969482422\n",
      "\n",
      " Train Epoch: 70 [60000/60000 (100%)]\tLoss: 0.008845\t accuracy: 99.65%\t Time: 0:00:09.390816\n",
      "\t Test loss: 0.3672251045703888 \t Test accuracy: 93.16999816894531\n",
      "\n",
      " Train Epoch: 71 [60000/60000 (100%)]\tLoss: 0.007774\t accuracy: 99.70%\t Time: 0:00:09.287584\n",
      "\t Test loss: 0.36474879682064054 \t Test accuracy: 93.3499984741211\n",
      "\n",
      " Train Epoch: 72 [60000/60000 (100%)]\tLoss: 0.007639\t accuracy: 99.67%\t Time: 0:00:09.321475\n",
      "\t Test loss: 0.35896356105804444 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 73 [60000/60000 (100%)]\tLoss: 0.006698\t accuracy: 99.74%\t Time: 0:00:09.371419\n",
      "\t Test loss: 0.35025014281272887 \t Test accuracy: 93.23999786376953\n",
      "\n",
      " Train Epoch: 74 [60000/60000 (100%)]\tLoss: 0.006346\t accuracy: 99.72%\t Time: 0:00:09.357987\n",
      "\t Test loss: 0.37449328005313876 \t Test accuracy: 93.38999938964844\n",
      "\n",
      " Train Epoch: 75 [60000/60000 (100%)]\tLoss: 0.006878\t accuracy: 99.72%\t Time: 0:00:09.312526\n",
      "\t Test loss: 0.3716102600097656 \t Test accuracy: 93.18999481201172\n",
      "\n",
      " Train Epoch: 76 [60000/60000 (100%)]\tLoss: 0.007186\t accuracy: 99.70%\t Time: 0:00:09.319189\n",
      "\t Test loss: 0.3708547502756119 \t Test accuracy: 93.27999877929688\n",
      "\n",
      " Train Epoch: 77 [60000/60000 (100%)]\tLoss: 0.007063\t accuracy: 99.72%\t Time: 0:00:09.357602\n",
      "\t Test loss: 0.3772864371538162 \t Test accuracy: 93.14999389648438\n",
      "\n",
      " Train Epoch: 78 [60000/60000 (100%)]\tLoss: 0.006182\t accuracy: 99.72%\t Time: 0:00:09.341837\n",
      "\t Test loss: 0.37167791426181795 \t Test accuracy: 93.37999725341797\n",
      "\n",
      " Train Epoch: 79 [60000/60000 (100%)]\tLoss: 0.005693\t accuracy: 99.77%\t Time: 0:00:09.291335\n",
      "\t Test loss: 0.37761319875717164 \t Test accuracy: 93.25\n",
      "\n",
      " Train Epoch: 80 [60000/60000 (100%)]\tLoss: 0.007354\t accuracy: 99.71%\t Time: 0:00:09.270314\n",
      "\t Test loss: 0.37298767268657684 \t Test accuracy: 93.19999694824219\n",
      "\n",
      " Train Epoch: 81 [60000/60000 (100%)]\tLoss: 0.007477\t accuracy: 99.72%\t Time: 0:00:09.283907\n",
      "\t Test loss: 0.37060480415821073 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 82 [60000/60000 (100%)]\tLoss: 0.006524\t accuracy: 99.74%\t Time: 0:00:09.334848\n",
      "\t Test loss: 0.37784287333488464 \t Test accuracy: 93.36000061035156\n",
      "\n",
      " Train Epoch: 83 [60000/60000 (100%)]\tLoss: 0.005871\t accuracy: 99.76%\t Time: 0:00:09.295226\n",
      "\t Test loss: 0.3944758266210556 \t Test accuracy: 93.30999755859375\n",
      "\n",
      " Train Epoch: 84 [60000/60000 (100%)]\tLoss: 0.005332\t accuracy: 99.81%\t Time: 0:00:09.285315\n",
      "\t Test loss: 0.38701200783252715 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 85 [60000/60000 (100%)]\tLoss: 0.005328\t accuracy: 99.78%\t Time: 0:00:09.252280\n",
      "\t Test loss: 0.3849873661994934 \t Test accuracy: 93.29000091552734\n",
      "\n",
      " Train Epoch: 86 [60000/60000 (100%)]\tLoss: 0.004738\t accuracy: 99.82%\t Time: 0:00:09.271400\n",
      "\t Test loss: 0.37511946856975553 \t Test accuracy: 93.37999725341797\n",
      "\n",
      " Train Epoch: 87 [60000/60000 (100%)]\tLoss: 0.005275\t accuracy: 99.78%\t Time: 0:00:09.269518\n",
      "\t Test loss: 0.38675864934921267 \t Test accuracy: 93.29000091552734\n",
      "\n",
      " Train Epoch: 88 [60000/60000 (100%)]\tLoss: 0.005081\t accuracy: 99.79%\t Time: 0:00:09.314209\n",
      "\t Test loss: 0.38761823177337645 \t Test accuracy: 93.29000091552734\n",
      "\n",
      " Train Epoch: 89 [60000/60000 (100%)]\tLoss: 0.005658\t accuracy: 99.76%\t Time: 0:00:09.332965\n",
      "\t Test loss: 0.39428270161151885 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 90 [60000/60000 (100%)]\tLoss: 0.005445\t accuracy: 99.77%\t Time: 0:00:10.057441\n",
      "\t Test loss: 0.39164571464061737 \t Test accuracy: 93.33999633789062\n",
      "\n",
      " Train Epoch: 91 [60000/60000 (100%)]\tLoss: 0.004932\t accuracy: 99.83%\t Time: 0:00:09.300570\n",
      "\t Test loss: 0.3919877946376801 \t Test accuracy: 93.41999816894531\n",
      "\n",
      " Train Epoch: 92 [60000/60000 (100%)]\tLoss: 0.004805\t accuracy: 99.81%\t Time: 0:00:09.293940\n",
      "\t Test loss: 0.39280240833759306 \t Test accuracy: 93.36000061035156\n",
      "\n",
      " Train Epoch: 93 [60000/60000 (100%)]\tLoss: 0.005189\t accuracy: 99.79%\t Time: 0:00:09.282728\n",
      "\t Test loss: 0.39918738305568696 \t Test accuracy: 93.23999786376953\n",
      "\n",
      " Train Epoch: 94 [60000/60000 (100%)]\tLoss: 0.004558\t accuracy: 99.81%\t Time: 0:00:09.232582\n",
      "\t Test loss: 0.3951236218214035 \t Test accuracy: 93.32999420166016\n",
      "\n",
      " Train Epoch: 95 [60000/60000 (100%)]\tLoss: 0.003701\t accuracy: 99.85%\t Time: 0:00:09.322664\n",
      "\t Test loss: 0.408807584643364 \t Test accuracy: 93.23999786376953\n",
      "\n",
      " Train Epoch: 96 [60000/60000 (100%)]\tLoss: 0.004463\t accuracy: 99.81%\t Time: 0:00:09.304266\n",
      "\t Test loss: 0.40878275632858274 \t Test accuracy: 93.27999877929688\n",
      "\n",
      " Train Epoch: 97 [60000/60000 (100%)]\tLoss: 0.004084\t accuracy: 99.83%\t Time: 0:00:09.263469\n",
      "\t Test loss: 0.4117244064807892 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 98 [60000/60000 (100%)]\tLoss: 0.004955\t accuracy: 99.81%\t Time: 0:00:09.390013\n",
      "\t Test loss: 0.4092125505208969 \t Test accuracy: 93.25999450683594\n",
      "\n",
      " Train Epoch: 99 [60000/60000 (100%)]\tLoss: 0.004994\t accuracy: 99.79%\t Time: 0:00:09.358087\n",
      "\t Test loss: 0.4076308935880661 \t Test accuracy: 93.33999633789062\n",
      "\n",
      " Train Epoch: 100 [60000/60000 (100%)]\tLoss: 0.005438\t accuracy: 99.77%\t Time: 0:00:09.425125\n",
      "\t Test loss: 0.40811256468296053 \t Test accuracy: 93.25\n",
      "\n",
      " Train Epoch: 101 [60000/60000 (100%)]\tLoss: 0.003754\t accuracy: 99.86%\t Time: 0:00:09.416537\n",
      "\t Test loss: 0.41559899151325225 \t Test accuracy: 93.18999481201172\n",
      "\n",
      " Train Epoch: 102 [60000/60000 (100%)]\tLoss: 0.003794\t accuracy: 99.86%\t Time: 0:00:09.402298\n",
      "\t Test loss: 0.4127135783433914 \t Test accuracy: 93.13999938964844\n",
      "\n",
      " Train Epoch: 103 [60000/60000 (100%)]\tLoss: 0.003486\t accuracy: 99.88%\t Time: 0:00:09.375060\n",
      "\t Test loss: 0.41267190873622894 \t Test accuracy: 93.30999755859375\n",
      "\n",
      " Train Epoch: 104 [60000/60000 (100%)]\tLoss: 0.004111\t accuracy: 99.83%\t Time: 0:00:09.410248\n",
      "\t Test loss: 0.42278688549995425 \t Test accuracy: 93.27999877929688\n",
      "\n",
      " Train Epoch: 105 [60000/60000 (100%)]\tLoss: 0.003740\t accuracy: 99.86%\t Time: 0:00:09.481978\n",
      "\t Test loss: 0.41974216401576997 \t Test accuracy: 93.33999633789062\n",
      "\n",
      " Train Epoch: 106 [60000/60000 (100%)]\tLoss: 0.004068\t accuracy: 99.84%\t Time: 0:00:09.610759\n",
      "\t Test loss: 0.4199068546295166 \t Test accuracy: 93.48999786376953\n",
      "\n",
      " Train Epoch: 107 [60000/60000 (100%)]\tLoss: 0.003016\t accuracy: 99.86%\t Time: 0:00:09.547814\n",
      "\t Test loss: 0.43008445799350736 \t Test accuracy: 93.43000030517578\n",
      "\n",
      " Train Epoch: 108 [60000/60000 (100%)]\tLoss: 0.002864\t accuracy: 99.89%\t Time: 0:00:09.513945\n",
      "\t Test loss: 0.42405453622341155 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 109 [60000/60000 (100%)]\tLoss: 0.002547\t accuracy: 99.90%\t Time: 0:00:09.454783\n",
      "\t Test loss: 0.42555989921092985 \t Test accuracy: 93.25999450683594\n",
      "\n",
      " Train Epoch: 110 [60000/60000 (100%)]\tLoss: 0.003202\t accuracy: 99.88%\t Time: 0:00:09.516128\n",
      "\t Test loss: 0.4292365849018097 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 111 [60000/60000 (100%)]\tLoss: 0.004130\t accuracy: 99.84%\t Time: 0:00:09.478109\n",
      "\t Test loss: 0.4228162169456482 \t Test accuracy: 93.06999969482422\n",
      "\n",
      " Train Epoch: 112 [60000/60000 (100%)]\tLoss: 0.003928\t accuracy: 99.84%\t Time: 0:00:09.493449\n",
      "\t Test loss: 0.43294128179550173 \t Test accuracy: 93.25999450683594\n",
      "\n",
      " Train Epoch: 113 [60000/60000 (100%)]\tLoss: 0.003097\t accuracy: 99.87%\t Time: 0:00:09.533542\n",
      "\t Test loss: 0.43482327163219453 \t Test accuracy: 93.14999389648438\n",
      "\n",
      " Train Epoch: 114 [60000/60000 (100%)]\tLoss: 0.003333\t accuracy: 99.87%\t Time: 0:00:09.473288\n",
      "\t Test loss: 0.43082004487514497 \t Test accuracy: 93.23999786376953\n",
      "\n",
      " Train Epoch: 115 [60000/60000 (100%)]\tLoss: 0.003839\t accuracy: 99.84%\t Time: 0:00:09.465365\n",
      "\t Test loss: 0.43327498733997344 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 116 [60000/60000 (100%)]\tLoss: 0.003570\t accuracy: 99.86%\t Time: 0:00:09.538697\n",
      "\t Test loss: 0.43573940694332125 \t Test accuracy: 93.33999633789062\n",
      "\n",
      " Train Epoch: 117 [60000/60000 (100%)]\tLoss: 0.003220\t accuracy: 99.86%\t Time: 0:00:09.418317\n",
      "\t Test loss: 0.443584731221199 \t Test accuracy: 93.3499984741211\n",
      "\n",
      " Train Epoch: 118 [60000/60000 (100%)]\tLoss: 0.003118\t accuracy: 99.88%\t Time: 0:00:09.429484\n",
      "\t Test loss: 0.4393545240163803 \t Test accuracy: 93.39999389648438\n",
      "\n",
      " Train Epoch: 119 [60000/60000 (100%)]\tLoss: 0.003104\t accuracy: 99.87%\t Time: 0:00:10.213200\n",
      "\t Test loss: 0.43042248785495757 \t Test accuracy: 93.2699966430664\n",
      "\n",
      " Train Epoch: 120 [60000/60000 (100%)]\tLoss: 0.003324\t accuracy: 99.88%\t Time: 0:00:09.400090\n",
      "\t Test loss: 0.44196840822696687 \t Test accuracy: 93.40999603271484\n",
      "\n",
      " Train Epoch: 121 [60000/60000 (100%)]\tLoss: 0.003846\t accuracy: 99.85%\t Time: 0:00:09.357984\n",
      "\t Test loss: 0.437187647819519 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 122 [60000/60000 (100%)]\tLoss: 0.003168\t accuracy: 99.87%\t Time: 0:00:09.588392\n",
      "\t Test loss: 0.43979112803936005 \t Test accuracy: 93.32999420166016\n",
      "\n",
      " Train Epoch: 123 [60000/60000 (100%)]\tLoss: 0.003395\t accuracy: 99.87%\t Time: 0:00:09.512102\n",
      "\t Test loss: 0.44317795932292936 \t Test accuracy: 93.38999938964844\n",
      "\n",
      " Train Epoch: 124 [60000/60000 (100%)]\tLoss: 0.003390\t accuracy: 99.85%\t Time: 0:00:09.499492\n",
      "\t Test loss: 0.44284993708133696 \t Test accuracy: 93.5199966430664\n",
      "\n",
      " Train Epoch: 125 [60000/60000 (100%)]\tLoss: 0.003621\t accuracy: 99.87%\t Time: 0:00:09.562116\n",
      "\t Test loss: 0.43577209413051604 \t Test accuracy: 93.5\n",
      "\n",
      " Train Epoch: 126 [60000/60000 (100%)]\tLoss: 0.002896\t accuracy: 99.88%\t Time: 0:00:09.532083\n",
      "\t Test loss: 0.4430164784193039 \t Test accuracy: 93.43000030517578\n",
      "\n",
      " Train Epoch: 127 [60000/60000 (100%)]\tLoss: 0.002633\t accuracy: 99.90%\t Time: 0:00:09.509023\n",
      "\t Test loss: 0.4488104432821274 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 128 [60000/60000 (100%)]\tLoss: 0.001955\t accuracy: 99.93%\t Time: 0:00:09.776599\n",
      "\t Test loss: 0.4528578549623489 \t Test accuracy: 93.27999877929688\n",
      "\n",
      " Train Epoch: 129 [60000/60000 (100%)]\tLoss: 0.001747\t accuracy: 99.93%\t Time: 0:00:09.598965\n",
      "\t Test loss: 0.4538241297006607 \t Test accuracy: 93.30999755859375\n",
      "\n",
      " Train Epoch: 130 [60000/60000 (100%)]\tLoss: 0.002478\t accuracy: 99.90%\t Time: 0:00:09.756776\n",
      "\t Test loss: 0.44560582637786866 \t Test accuracy: 93.5199966430664\n",
      "\n",
      " Train Epoch: 131 [60000/60000 (100%)]\tLoss: 0.002639\t accuracy: 99.90%\t Time: 0:00:09.626397\n",
      "\t Test loss: 0.451632359623909 \t Test accuracy: 93.47000122070312\n",
      "\n",
      " Train Epoch: 132 [60000/60000 (100%)]\tLoss: 0.002092\t accuracy: 99.92%\t Time: 0:00:09.515152\n",
      "\t Test loss: 0.4488516688346863 \t Test accuracy: 93.29000091552734\n",
      "\n",
      " Train Epoch: 133 [60000/60000 (100%)]\tLoss: 0.001388\t accuracy: 99.96%\t Time: 0:00:09.484489\n",
      "\t Test loss: 0.4570650726556778 \t Test accuracy: 93.38999938964844\n",
      "\n",
      " Train Epoch: 134 [60000/60000 (100%)]\tLoss: 0.001589\t accuracy: 99.94%\t Time: 0:00:09.560250\n",
      "\t Test loss: 0.4589389204978943 \t Test accuracy: 93.30999755859375\n",
      "\n",
      " Train Epoch: 135 [60000/60000 (100%)]\tLoss: 0.001780\t accuracy: 99.94%\t Time: 0:00:09.611339\n",
      "\t Test loss: 0.4525360196828842 \t Test accuracy: 93.48999786376953\n",
      "\n",
      " Train Epoch: 136 [60000/60000 (100%)]\tLoss: 0.002332\t accuracy: 99.92%\t Time: 0:00:09.537915\n",
      "\t Test loss: 0.46410867273807527 \t Test accuracy: 93.40999603271484\n",
      "\n",
      " Train Epoch: 137 [60000/60000 (100%)]\tLoss: 0.001503\t accuracy: 99.95%\t Time: 0:00:09.601598\n",
      "\t Test loss: 0.4590067744255066 \t Test accuracy: 93.3699951171875\n",
      "\n",
      " Train Epoch: 138 [60000/60000 (100%)]\tLoss: 0.002142\t accuracy: 99.91%\t Time: 0:00:09.528700\n",
      "\t Test loss: 0.4646662950515747 \t Test accuracy: 93.32999420166016\n",
      "\n",
      " Train Epoch: 139 [60000/60000 (100%)]\tLoss: 0.001681\t accuracy: 99.93%\t Time: 0:00:09.493583\n",
      "\t Test loss: 0.4564815104007721 \t Test accuracy: 93.44999694824219\n",
      "\n",
      " Train Epoch: 140 [60000/60000 (100%)]\tLoss: 0.002054\t accuracy: 99.92%\t Time: 0:00:09.492182\n",
      "\t Test loss: 0.46638724505901336 \t Test accuracy: 93.3499984741211\n",
      "\n",
      " Train Epoch: 141 [60000/60000 (100%)]\tLoss: 0.002446\t accuracy: 99.90%\t Time: 0:00:09.449618\n",
      "\t Test loss: 0.46491379141807554 \t Test accuracy: 93.22999572753906\n",
      "\n",
      " Train Epoch: 142 [60000/60000 (100%)]\tLoss: 0.001882\t accuracy: 99.93%\t Time: 0:00:09.519320\n",
      "\t Test loss: 0.46468465924263 \t Test accuracy: 93.30999755859375\n",
      "\n",
      " Train Epoch: 143 [60000/60000 (100%)]\tLoss: 0.001290\t accuracy: 99.96%\t Time: 0:00:09.539614\n",
      "\t Test loss: 0.4620191156864166 \t Test accuracy: 93.43000030517578\n",
      "\n",
      " Train Epoch: 144 [60000/60000 (100%)]\tLoss: 0.001715\t accuracy: 99.93%\t Time: 0:00:09.476552\n",
      "\t Test loss: 0.47348441183567047 \t Test accuracy: 93.32999420166016\n",
      "\n",
      " Train Epoch: 145 [60000/60000 (100%)]\tLoss: 0.001296\t accuracy: 99.95%\t Time: 0:00:09.518245\n",
      "\t Test loss: 0.4692289590835571 \t Test accuracy: 93.3499984741211\n",
      "\n",
      " Train Epoch: 146 [60000/60000 (100%)]\tLoss: 0.001609\t accuracy: 99.94%\t Time: 0:00:09.491765\n",
      "\t Test loss: 0.46615682542324066 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 147 [60000/60000 (100%)]\tLoss: 0.001759\t accuracy: 99.93%\t Time: 0:00:09.478107\n",
      "\t Test loss: 0.46311271786689756 \t Test accuracy: 93.37999725341797\n",
      "\n",
      " Train Epoch: 148 [60000/60000 (100%)]\tLoss: 0.001421\t accuracy: 99.95%\t Time: 0:00:09.590809\n",
      "\t Test loss: 0.4695258170366287 \t Test accuracy: 93.38999938964844\n",
      "\n",
      " Train Epoch: 149 [60000/60000 (100%)]\tLoss: 0.001732\t accuracy: 99.94%\t Time: 0:00:09.962467\n",
      "\t Test loss: 0.46802498400211334 \t Test accuracy: 93.36000061035156\n",
      "\n",
      " Train Epoch: 150 [60000/60000 (100%)]\tLoss: 0.002093\t accuracy: 99.92%\t Time: 0:00:09.514167\n",
      "\t Test loss: 0.4736798942089081 \t Test accuracy: 93.25999450683594\n",
      "\n",
      " Train Epoch: 151 [60000/60000 (100%)]\tLoss: 0.001781\t accuracy: 99.93%\t Time: 0:00:09.505056\n",
      "\t Test loss: 0.4760215163230896 \t Test accuracy: 93.25\n",
      "\n",
      " Train Epoch: 152 [60000/60000 (100%)]\tLoss: 0.001210\t accuracy: 99.97%\t Time: 0:00:09.518970\n",
      "\t Test loss: 0.47661066949367525 \t Test accuracy: 93.43000030517578\n",
      "\n",
      " Train Epoch: 153 [60000/60000 (100%)]\tLoss: 0.001370\t accuracy: 99.95%\t Time: 0:00:09.542597\n",
      "\t Test loss: 0.48387548327445984 \t Test accuracy: 93.2699966430664\n",
      "\n",
      " Train Epoch: 154 [60000/60000 (100%)]\tLoss: 0.001759\t accuracy: 99.94%\t Time: 0:00:09.504894\n",
      "\t Test loss: 0.4755702495574951 \t Test accuracy: 93.25999450683594\n",
      "\n",
      " Train Epoch: 155 [60000/60000 (100%)]\tLoss: 0.001299\t accuracy: 99.95%\t Time: 0:00:09.476918\n",
      "\t Test loss: 0.4823435515165329 \t Test accuracy: 93.3699951171875\n",
      "\n",
      " Train Epoch: 156 [60000/60000 (100%)]\tLoss: 0.001845\t accuracy: 99.93%\t Time: 0:00:09.491638\n",
      "\t Test loss: 0.4797886490821838 \t Test accuracy: 93.32999420166016\n",
      "\n",
      " Train Epoch: 157 [60000/60000 (100%)]\tLoss: 0.001658\t accuracy: 99.94%\t Time: 0:00:09.493441\n",
      "\t Test loss: 0.47898799180984497 \t Test accuracy: 93.23999786376953\n",
      "\n",
      " Train Epoch: 158 [60000/60000 (100%)]\tLoss: 0.001860\t accuracy: 99.94%\t Time: 0:00:09.532343\n",
      "\t Test loss: 0.4795629233121872 \t Test accuracy: 93.3699951171875\n",
      "\n",
      " Train Epoch: 159 [60000/60000 (100%)]\tLoss: 0.002063\t accuracy: 99.93%\t Time: 0:00:09.535227\n",
      "\t Test loss: 0.48379203379154206 \t Test accuracy: 93.3699951171875\n",
      "\n",
      " Train Epoch: 160 [60000/60000 (100%)]\tLoss: 0.001464\t accuracy: 99.95%\t Time: 0:00:09.545256\n",
      "\t Test loss: 0.48315146565437317 \t Test accuracy: 93.36000061035156\n",
      "\n",
      " Train Epoch: 161 [60000/60000 (100%)]\tLoss: 0.001288\t accuracy: 99.94%\t Time: 0:00:09.515149\n",
      "\t Test loss: 0.48493083715438845 \t Test accuracy: 93.41999816894531\n",
      "\n",
      " Train Epoch: 162 [60000/60000 (100%)]\tLoss: 0.002047\t accuracy: 99.90%\t Time: 0:00:09.523379\n",
      "\t Test loss: 0.4789374828338623 \t Test accuracy: 93.2699966430664\n",
      "\n",
      " Train Epoch: 163 [60000/60000 (100%)]\tLoss: 0.000955\t accuracy: 99.97%\t Time: 0:00:09.482120\n",
      "\t Test loss: 0.48651803135871885 \t Test accuracy: 93.45999908447266\n",
      "\n",
      " Train Epoch: 164 [60000/60000 (100%)]\tLoss: 0.001085\t accuracy: 99.96%\t Time: 0:00:09.678957\n",
      "\t Test loss: 0.4825561702251434 \t Test accuracy: 93.25\n",
      "\n",
      " Train Epoch: 165 [60000/60000 (100%)]\tLoss: 0.001108\t accuracy: 99.96%\t Time: 0:00:09.518950\n",
      "\t Test loss: 0.5003556042909623 \t Test accuracy: 93.32999420166016\n",
      "\n",
      " Train Epoch: 166 [60000/60000 (100%)]\tLoss: 0.001013\t accuracy: 99.96%\t Time: 0:00:09.499386\n",
      "\t Test loss: 0.4991769134998322 \t Test accuracy: 93.33999633789062\n",
      "\n",
      " Train Epoch: 167 [60000/60000 (100%)]\tLoss: 0.001288\t accuracy: 99.94%\t Time: 0:00:09.599390\n",
      "\t Test loss: 0.5020662009716034 \t Test accuracy: 93.30999755859375\n",
      "\n",
      " Train Epoch: 168 [60000/60000 (100%)]\tLoss: 0.001129\t accuracy: 99.97%\t Time: 0:00:09.541531\n",
      "\t Test loss: 0.5101614683866501 \t Test accuracy: 93.20999908447266\n",
      "\n",
      " Train Epoch: 169 [60000/60000 (100%)]\tLoss: 0.001071\t accuracy: 99.96%\t Time: 0:00:09.526811\n",
      "\t Test loss: 0.5105735778808593 \t Test accuracy: 93.31999969482422\n",
      "\n",
      " Train Epoch: 170 [60000/60000 (100%)]\tLoss: 0.000837\t accuracy: 99.97%\t Time: 0:00:09.545031\n",
      "\t Test loss: 0.5088773131370544 \t Test accuracy: 93.32999420166016\n",
      "\n",
      " Train Epoch: 171 [60000/60000 (100%)]\tLoss: 0.000973\t accuracy: 99.97%\t Time: 0:00:09.562944\n",
      "\t Test loss: 0.49551807045936586 \t Test accuracy: 93.40999603271484\n",
      "\n",
      " Train Epoch: 172 [60000/60000 (100%)]\tLoss: 0.000867\t accuracy: 99.98%\t Time: 0:00:09.517565\n",
      "\t Test loss: 0.505307388305664 \t Test accuracy: 93.45999908447266\n",
      "\n",
      " Train Epoch: 173 [60000/60000 (100%)]\tLoss: 0.000874\t accuracy: 99.97%\t Time: 0:00:09.528023\n",
      "\t Test loss: 0.49806272983551025 \t Test accuracy: 93.5\n",
      "\n",
      " Train Epoch: 174 [60000/60000 (100%)]\tLoss: 0.000659\t accuracy: 99.98%\t Time: 0:00:09.562428\n",
      "\t Test loss: 0.5043317556381226 \t Test accuracy: 93.3699951171875\n",
      "\n",
      " Train Epoch: 175 [60000/60000 (100%)]\tLoss: 0.000641\t accuracy: 99.99%\t Time: 0:00:09.523303\n",
      "\t Test loss: 0.5092911750078202 \t Test accuracy: 93.40999603271484\n",
      "\n",
      " Train Epoch: 176 [60000/60000 (100%)]\tLoss: 0.000395\t accuracy: 99.99%\t Time: 0:00:09.595521\n",
      "\t Test loss: 0.5109501361846924 \t Test accuracy: 93.47999572753906\n",
      "\n",
      " Train Epoch: 177 [60000/60000 (100%)]\tLoss: 0.000445\t accuracy: 100.00%\t Time: 0:00:09.514351\n",
      "\t Test loss: 0.5134999096393585 \t Test accuracy: 93.43999481201172\n",
      "\n",
      " Train Epoch: 178 [60000/60000 (100%)]\tLoss: 0.000935\t accuracy: 99.97%\t Time: 0:00:10.267449\n",
      "\t Test loss: 0.511391070485115 \t Test accuracy: 93.47000122070312\n",
      "\n",
      " Train Epoch: 179 [60000/60000 (100%)]\tLoss: 0.000639\t accuracy: 99.99%\t Time: 0:00:09.491346\n",
      "\t Test loss: 0.5124162316322327 \t Test accuracy: 93.41999816894531\n",
      "\n",
      " Train Epoch: 180 [60000/60000 (100%)]\tLoss: 0.000477\t accuracy: 99.99%\t Time: 0:00:09.538351\n",
      "\t Test loss: 0.5157376080751419 \t Test accuracy: 93.31999969482422\n",
      "\n",
      " Train Epoch: 181 [60000/60000 (100%)]\tLoss: 0.000719\t accuracy: 99.98%\t Time: 0:00:09.559162\n",
      "\t Test loss: 0.5194885849952697 \t Test accuracy: 93.45999908447266\n",
      "\n",
      " Train Epoch: 182 [60000/60000 (100%)]\tLoss: 0.000535\t accuracy: 99.99%\t Time: 0:00:09.534085\n",
      "\t Test loss: 0.5128354221582413 \t Test accuracy: 93.40999603271484\n",
      "\n",
      " Train Epoch: 183 [60000/60000 (100%)]\tLoss: 0.000407\t accuracy: 99.99%\t Time: 0:00:09.583695\n",
      "\t Test loss: 0.5177047729492188 \t Test accuracy: 93.52999877929688\n",
      "\n",
      " Train Epoch: 184 [60000/60000 (100%)]\tLoss: 0.000226\t accuracy: 100.00%\t Time: 0:00:09.537331\n",
      "\t Test loss: 0.5204257160425186 \t Test accuracy: 93.48999786376953\n",
      "\n",
      " Train Epoch: 185 [60000/60000 (100%)]\tLoss: 0.000246\t accuracy: 100.00%\t Time: 0:00:09.477034\n",
      "\t Test loss: 0.5193239152431488 \t Test accuracy: 93.43000030517578\n",
      "\n",
      " Train Epoch: 186 [60000/60000 (100%)]\tLoss: 0.000540\t accuracy: 99.98%\t Time: 0:00:09.488280\n",
      "\t Test loss: 0.5213761746883392 \t Test accuracy: 93.38999938964844\n",
      "\n",
      " Train Epoch: 187 [60000/60000 (100%)]\tLoss: 0.001122\t accuracy: 99.96%\t Time: 0:00:09.501423\n",
      "\t Test loss: 0.5209697097539902 \t Test accuracy: 93.43000030517578\n",
      "\n",
      " Train Epoch: 188 [60000/60000 (100%)]\tLoss: 0.000388\t accuracy: 99.99%\t Time: 0:00:09.533397\n",
      "\t Test loss: 0.5173685163259506 \t Test accuracy: 93.43999481201172\n",
      "\n",
      " Train Epoch: 189 [60000/60000 (100%)]\tLoss: 0.000515\t accuracy: 99.98%\t Time: 0:00:09.523869\n",
      "\t Test loss: 0.5196193248033524 \t Test accuracy: 93.41999816894531\n",
      "\n",
      " Train Epoch: 190 [60000/60000 (100%)]\tLoss: 0.001001\t accuracy: 99.97%\t Time: 0:00:09.622504\n",
      "\t Test loss: 0.5216112703084945 \t Test accuracy: 93.41999816894531\n",
      "\n",
      " Train Epoch: 191 [60000/60000 (100%)]\tLoss: 0.000571\t accuracy: 99.98%\t Time: 0:00:09.575853\n",
      "\t Test loss: 0.523773518204689 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 192 [60000/60000 (100%)]\tLoss: 0.001225\t accuracy: 99.95%\t Time: 0:00:09.511558\n",
      "\t Test loss: 0.5169226408004761 \t Test accuracy: 93.39999389648438\n",
      "\n",
      " Train Epoch: 193 [60000/60000 (100%)]\tLoss: 0.000758\t accuracy: 99.97%\t Time: 0:00:09.551434\n",
      "\t Test loss: 0.5187291175127029 \t Test accuracy: 93.29999542236328\n",
      "\n",
      " Train Epoch: 194 [60000/60000 (100%)]\tLoss: 0.000708\t accuracy: 99.98%\t Time: 0:00:09.555560\n",
      "\t Test loss: 0.5206519484519958 \t Test accuracy: 93.31999969482422\n",
      "\n",
      " Train Epoch: 195 [60000/60000 (100%)]\tLoss: 0.000777\t accuracy: 99.98%\t Time: 0:00:09.525462\n",
      "\t Test loss: 0.5217676252126694 \t Test accuracy: 93.5\n",
      "\n",
      " Train Epoch: 196 [60000/60000 (100%)]\tLoss: 0.000957\t accuracy: 99.97%\t Time: 0:00:09.481147\n",
      "\t Test loss: 0.5247333139181137 \t Test accuracy: 93.47000122070312\n",
      "\n",
      " Train Epoch: 197 [60000/60000 (100%)]\tLoss: 0.000969\t accuracy: 99.97%\t Time: 0:00:09.518456\n",
      "\t Test loss: 0.5157062143087388 \t Test accuracy: 93.41999816894531\n",
      "\n",
      " Train Epoch: 198 [60000/60000 (100%)]\tLoss: 0.000911\t accuracy: 99.97%\t Time: 0:00:09.478582\n",
      "\t Test loss: 0.5178808122873306 \t Test accuracy: 93.45999908447266\n",
      "\n",
      " Train Epoch: 199 [60000/60000 (100%)]\tLoss: 0.000769\t accuracy: 99.97%\t Time: 0:00:09.511959\n",
      "\t Test loss: 0.5241554617881775 \t Test accuracy: 93.45999908447266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_model(ARCHITECTURE, DATASET).to(device)\n",
    "\n",
    "# Specifying the background-optimizer of SAM. This can be changed to any optimizer that is supported by PyTorch. Examples:\n",
    "# In order to use PHB:        optimizer = SAM(model.parameters(), torch.optim.SGD, lr=0.1, momentum=0.8)\n",
    "# In order to use Adam:       optimizer = SAM(model.parameters(), torch.optim.Adam)\n",
    "# In order to use AdaBound:   optimizer = SAM(model.parameters(), AdaBound)\n",
    "# In order to use AdaShift:   optimizer = SAM(model.parameters(), AdaShift)\n",
    "optimizer = SAM(model.parameters(), torch.optim.SGD, lr=0.1)\n",
    "\n",
    "sam_optimizer_name = 'SAM_' + optimizer_name\n",
    "model = train(model, optimizer, train_loader=train_loader, device=device, epoch_num=MAX_EPOCH, max_nbr_epochs=MAX_EPOCH, path=sam_optimizer_name, val_dataloader=test_loader, sam=True, dir_path=store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "lr = 0.1 if DATASET == 'FashionMNIST' else 1\n",
    "num_epochs = 100000\n",
    "computed = False\n",
    "batch_size = 128\n",
    "\n",
    "path = os.path.join(store_dir, 'epoch200', sam_optimizer_name + '.pt')\n",
    "checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "model = checkpoint['state_dict']\n",
    "model = get_model(ARCHITECTURE, DATASET).to(device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "while not computed:\n",
    "    try:\n",
    "        # Calculating the sharpness. Returns an error if the learning rate is too big\n",
    "        sharpnesses, losses = minimum_shaprness_eff(data, model, batch_size, lr, num_epochs=num_epochs, optimizer_file=path)\n",
    "\n",
    "        # storing the sharpness\n",
    "        sharpness_path = os.path.join(store_dir, 'epoch200', sam_optimizer_name + '_sharpness.pt')\n",
    "        checkpoint = {'sharpnesses':sharpnesses, 'sharpness':sharpnesses[-1], 'losses': losses}\n",
    "        torch.save(checkpoint, sharpness_path)\n",
    "\n",
    "        # Plotting sharpness as an objective function being minimized during time\n",
    "        plt.ylabel('Sharpness')\n",
    "        plt.xlabel('Epoch [x100]')\n",
    "        plt.plot(sharpnesses)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        computed = True\n",
    "        print(f'Sharpness: {sharpnesses[-1]}')\n",
    "    except:\n",
    "        # Error is returned if the learning rate is too big, so in that case learning rate is set to be twice smaller and number of epochs are set to be twice as bigger\n",
    "        computed = False\n",
    "        lr /= 2.0\n",
    "        num_epochs *= 2\n",
    "        print(f'Use smaller stepsize than {lr}')"
   ],
   "metadata": {
    "id": "iPLBIguqajZW",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "f072fc44-6f2f-463f-b3ea-d96d29934bf6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\t Calculating Hessian\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tFinished the diag calculation. Time needed: 0:01:01.459540. Computing sharpness...\n",
      " \t\t epoch:100000\t processed 100.0%\t loss:0.016041555268829076 \t minimum sharpness: 28238.661864613856 \t Time needed 0:01:46.752965\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sharpness: 28238.661864613856\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data"
   ],
   "metadata": {
    "id": "Th3AcINbffKZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we demonstrate how to load the data. We compare here SGD and SAM with SGD. Plots used in the report are shown in the *Data analysis* notebook."
   ],
   "metadata": {
    "id": "A-5nn6CHfic_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading information about SGD training\n",
    "checkpoint_sgd = torch.load(os.path.join(store_dir, 'epoch200', optimizer_name + '.pt'), map_location=torch.device('cpu'))\n",
    "losses_sgd = checkpoint_sgd['training_loss']\n",
    "acc_sgd = checkpoint_sgd['validation_accuracy']\n",
    "sharpness_sgd = torch.load(os.path.join(store_dir, 'epoch200', optimizer_name + '_sharpness.pt'))['sharpness']\n",
    "\n",
    "# Loading information about SAM SGD training\n",
    "#checkpoint_sam = torch.load(os.path.join(store_dir, 'epoch200', 'SAM_SGD.pt'), map_location=torch.device('cpu'))\n",
    "checkpoint_sam = torch.load(os.path.join(store_dir, 'epoch200', sam_optimizer_name + '.pt'), map_location=torch.device('cpu'))\n",
    "losses_sam = checkpoint_sam['training_loss']\n",
    "acc_sam = checkpoint_sam['validation_accuracy']\n",
    "sharpness_sam = torch.load(os.path.join(store_dir, 'epoch200', sam_optimizer_name + '_sharpness.pt'))['sharpness']\n",
    "\n",
    "# Plotting both\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].loglog(losses_sgd, label='SGD')\n",
    "ax[0].loglog(losses_sam, label='SAM')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Training loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].loglog(acc_sgd, label='SGD')\n",
    "ax[1].loglog(acc_sam, label='SAM')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Test accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "# Writing sharpness\n",
    "print(f'Minimum sharpness of SGD: {sharpness_sgd}')\n",
    "print(f'Minimum sharpness of SAM: {sharpness_sam}')"
   ],
   "metadata": {
    "id": "FxXQqjg4fe23",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "outputId": "a19c5174-e52d-4609-a00f-6336610f8ad9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum sharpness of SGD: 108900.66487971791\n",
      "Minimum sharpness of SAM: 28238.661864613856\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABdT0lEQVR4nO2dd3hUVfrHPyeT3kknQAih994UBBR7wY7YEVl1F2zrT9e197LrrnVdcBGxgaKIilgAUURReu+dUJKQkF5n5vz+OJNKyqTMTAjv53nuM3PPPffc905u5jvnnPe8r9JaIwiCIAjuxMvTBgiCIAinHyI+giAIgtsR8REEQRDcjoiPIAiC4HZEfARBEAS3I+IjCIIguB1vTxtwKhAVFaUTExM9bYYgCMIpxZo1a45rraOrOybi4wSJiYmsXr3a02YIgiCcUiilDtR0TIbdBEEQBLcj4iMIgiC4HREfQRAEwe3InI8gCIILKSkpITk5mcLCQk+b4jL8/f1p27YtPj4+Tp8j4uMMBZmweV7Dz7f4gMUPvH3LX739Ty6z+IG3H3hZmsx0QRA8S3JyMiEhISQmJqKU8rQ5TY7WmvT0dJKTk+nQoYPT54n4OMOJffDZRPddT1mMCFl8Ha9VxKnSserqVKhrcQjdSWUVjvkEgG+QefUJNO8tvtAC/1EEwd0UFha2WOEBUEoRGRlJWlpavc4T8XGCQ97tuT/q+Qadq9D4WzTBFhtB3jYCvWwEelnx97ISUPqqbPipEnyxlr366BJ8sOKji/HWxXjrEiz2YrzsxXjZisFaCIVZYCsGa1GF1yKwOo7TiHQZynKyIPkEgm+geS1776hT+r7GsirnWOTRE04fWqrwlNKQ+5NvACcoUX4c9mnfoHM1UGy1U1hko7DERkGJjcISOwUlNoqt9ga16WNR+PtY8PexEOBjwd/HiwAfC36BFfa9vQj0gWCLjUCL3SF+VgK8bARYjOAFeFkJUFYCVRGBqogAivCnGB9bAV7WfCjOh5I8KCkof1+cD3np5e9L8qE4D7Stfjdh8XUIWwVxqlbsgsA/HPzDzBZQ4b1/mDnmEyC9NEGog+eee46PP/4Yi8WCl5cX06ZNY+DAgTz++OPMnTuXoKAgAK655hoeeeQRACwWC71796akpARvb29uvvlm7rvvPry8Gu+rJuLjBEnRQXxyx/Amb9dm1xRZbRQU2yi02s1rSelmdwiVEayiKsJVUGwrP7dC3cz84pPOLSyxUWKrrhekAB/HFlxeqiDY15tgf2+C/cpfQ/y9CQ73JtjPh2B/b0IqHvOxE2YpIcRSTLBXEUGqhAAK8baVCldBZcEqya8saKXHC7Mh55gRtJICKM41dWvDy6dmYapWtMLLjwVGyByb0OJZsWIFCxYsYO3atfj5+XH8+HGKi4t59NFHOXbsGJs2bcLf35+cnBxeeeWVsvMCAgJYv349AKmpqVx//fVkZ2fz1FNPNdomER8PYvFSBPp6E+jr+j+D1Wan0Go3glQmXEak8oqs5BRZyS20kltUQm5hxX2z5RRaOZpVWKnMGYL9vAkPDKZVYAThgT60CvSlVaAPrYJ8aRXuW6HM8T7IlyBfS+VuvK3EDDEWZkFhpnEAqbhf9j6r/FjmofK69pKaDVReEBQNwTEQHAfBseZ9SJyjLLZ88wuuuR1BaMYcPXqUqKgo/Pz8AIiKiiI/P5933nmH/fv34+/vD0BISAhPPvlktW3ExMQwffp0Bg8ezJNPPtnooUQRn9MEb4sXwRYvgv2a5k9ut2vyih1CVFWsHPs5hSVkFZSQmV9CRl4xmfnFHEjP50R+MTmFNYuXr8WrXJSCfIgN9Scu1J+YUH9iQ1sTF9qB2Hh/okP88Pepo9eitZn/qk6wCjIhLxVyUyAnxbymbDFl9mrs8wmCkNhygQqOM/th7SC0DYS1hdB4490oCNXw1Ndb2Hoku0nb7BEfyhOX9qy1znnnncfTTz9Nly5dGDt2LOPHj6dVq1YkJCQQEhLi9LWSkpKw2WykpqYSGxvbKLtFfIQG4eWlCPH3IcTfB8Lqf36Jze4QpmIy8ko4kW/E6US+472jLD2vmLUHT5CSXVTtHFmrQCNOMaH+xIX6VXjvT2yoH3Gh/kQG+2MJbQ2hrZ0zzm6HggwjRhWFKTcVco+Z19RtsOcnKMqqcrIyvabQNhDWprIwle4HRcscleBWgoODWbNmDb/88gtLly5l/Pjx/P3vf69UZ+bMmbz22mukp6fz22+/0a5dO5faJOIjeAQfixdRwX5EBfs5VV9rTWZ+CSk5haRkF5GSVUhKdiEpOYUcyyoiNaeQHceyScspwl5lestLQXSIX4XeU/n79hGBdIgKIjrEr3wYwcsLgqLMFlv7L0qK8yDrMGQnQ1ayeZ+VbPZTtsDOH8BaUOXmgyC6K8T0gJhuEN3dvIa2EVFq4dTVQ3ElFouF0aNHM3r0aHr37s20adM4ePAgOTk5hISEMHHiRCZOnEivXr2w2ap3INq7dy8Wi4WYmJhG2yPiI5wSKKXMPFGQL93iaq5ntdlJzysmJbuQY1mFpOQUkVrh/aGMfFbtzyAzv/I8UJCvhQ7RQSRGBpEUFURiVBAdooJIigomLLCWYTTfIIjuYrbq0BryMyqIUzKk74G0bbDrB1j/YXldv1AjStHdIKa7eY3uZobyRJSERrBjxw68vLzo3LkzAOvXr6dr167079+fKVOmMG3aNPz9/bHZbBQXF1fbRlpaGnfeeSdTpkxpEtdxER+hReFt8SI21J/YUH/6tK25XmGJjZTsQg6k57PveF7ZtulwFgs3Ha3Ue4oJ8aNrXAhdYkPoGhtCl7gQOscEE+TM/JlSEBRpttZ9Tz6el26EKHUbpG2H1O2wYyGs+6C8jm+IQ+AcYtS6D8T1MZ56guAEubm5TJ06lczMTLy9venUqRPTp08nLCyMxx57jF69ehESEkJAQAC33HIL8fHxABQUFNCvX78yV+ubbrqJ+++/v0lsUlo3YiHiacKgQYO05PM5fSi22jmYkc/+43nsPZ7LjmO57EzJYVdqDoUl5fNOCRGBdG8dwqD2EQzuEEHP+FB8LE0Uqzc3zYhS2g44vtMIU9pOM+dUSlg7I0Kt+xhhi+sjvaRmyLZt2+jevbunzXA51d2nUmqN1npQdfWl5yMIVfD19qJTTDCdYoKBco8em11zKCOfHSk57DiWw46UHDYlZ/H9lhQAAnws9E8IZ3BiBIMTI+ifEO5c76g6gqPN1uGsyuV56XBsAxzdCMc2mtcdCymLZhEUAx3HQKdzoePZpsclCM0QER9BcBKLlyLRMR90fs/yiaeU7EJW7c9g9f4TrNyXwes/7kJr4+jQOSaEvu3C6NeuFX3bhdE1NgTvxvSOgiKNqHQ8u7ysKNc4NxzbCIf+gN2LYeMngDI9osQR0P5MaD8cAlo1/NqC0IR4ZNhNKXUmsF5rnaeUuhEYALymta4x5aonkWE3oT5kF5aw9sAJ1h3MZENyJhsOZXLC4eDg7+PFwPatGNs9lrHdY2kXEdj0BtjtcHQd7FoM+5ZB8ioT8w8Fsb0g8UwjRq37GhdwifDgUmTYrfphN0+Jz0agL9AHeA/4H3Ct1nqU241xAhEfoTForTmYkc/6Q5msP5TJL7uOszs1F4BucSGc1yOWc3vE0atNqGsCUJYUwuE1cOBX2L8cDq0sd/+2+EFkR2g7CHpcbob5ZJFskyLi07zEZ63WeoBS6nHgsNZ6RmmZ241xAhEfoanZdzyPRVuPsXhrKqsPZGDX0CEqiMv7teHy/vG0jwxy3cWtxXB0vfGwS98Fx3cZUSrONcNy7c8sd/fueLZ41TUSEZ/m5XCQo5R6GLgROEsp5YWJbikIpwUdooL401kd+dNZHUnPLWLxthTmrzvCq0t28u/FOxmQEM7l/dtwQc84YkL9m/bi3r7QbojZSikpgN1LYNtXcHgt7PjWRCq3+EK3S6DvBNM7EiESmghP9XzigOuBVVrrX5RSCcBorfX7bjfGCaTnI7iLI5kFfLn+CF+sS2Znihma69sunPN6mDmiLrHB7skNYy2ClM2w8VPjvFBwwpSHJZh5Ip8AEwGi60XQ5XyzL1RLc+n5VJdSYejQoVitVlq3bs2kSZN48cUXy+qPHj2avXv3cuDAgbJn7vLLL2fx4sXk5uae1P4p0/PBOBjYlFJdgG7AbA/ZIgjNhvjwAO4a3ZE7RyWxMyWXRVuPsWhrCv/4fgf/+H4HSVFBXNG/DVcMaEPbVi5wVijF2w/aDDTb2KfMfNGxjXBsk4ltV5gJRzcYYfIJMukprIUm6GriCOh8HnQaa0IVCR6nppQKAIsWLaJLly7MnTuXF154odKPm/DwcH799VdGjBhBZmYmR48ebTKbPCU+y4CRSqlWwA/AKmA8cIOH7BGEZoVSiq5xIXSNC2HK2Z1JyS5k8bYUvlp/hFcW7eSVRTsZnhTJVQPbcmGvuIavJ3IGH3/odI7ZKmK3wf5fYNsC48Dg7Q8Z+2D9x7DqHYjqAgNugVbtIbKziV8neITqUiqUMnv2bO655x7efvttVqxYwRlnnFF27LrrrmPOnDmMGDGCefPmceWVV7Jly5YmscnTDgdTgQCt9ctKqQ1a62rij3geGXYTmhOHMvKZt/Yw89YlcyA9nwAfCxf2iuOqgW0ZnhSJUpBXbCOroITwAB/XClN12Epg65fw66ump1RKm4HQ/TIzRBcYCfH9ISKpxUdkqDQc9e3fKn8mTUFcb7jwxVqr5ObmMmLECPLz88tSKowaNYrCwkKSkpLYs2cPH3zwAZs2beKNN94AzLDbSy+9xOTJk1m3bh0XXngh06dPp1evXqf0sJtSSg3H9HQmOcqkfy4ITtAuIpB7xnbm7nM6sebACT5fm8yCDUeZt+4wgb4Wiq12rI7gdCF+3kw+K4nbRnRoslxOdWLxgd5XQ6+rytNQHFgBq2fA4icq122VCH2vNwFVg6Kg7WAz5Cc0KdWlVHjxxRcJDg5mzJgxBAQEcNVVV/HMM8/w6quvYrGYtV8Wi4URI0YwZ84cCgoKSExMbDKbPCU+9wIPA19orbcopZKApR6yRRBOSZRSDEqMYFBiBE9c2pNFW1NYvT+DID9vwgJ8CA3wYen2VP61aCezftvPXaM7MmFIgvt6QkqZZHshsWZB69A7zFyR3Q45RyB5NWyZBz89X36Obwh0Oc942HU+12Sa3fqlST8R3889druSOnoorqRqSoVZs2bh6+vL8uXLy0QlPT2dH3/8kXPPPbfsvOuuu44rrriixgynDcUj4qO1/hn4WSkVrJQK1lrvBe72hC2C0BLw97Fwad94Lu0bX6l8wpAE1h08wT9/2MGz32zj1cW7uHJAG24Y2p6ucc5nsGwSlCoP7xMUaYaLBk00vaO845B5EHZ8A9sXwubPjZu3T6ARLOUFgyfD2Y+aMnuJeNjVg+pSKkRHR7NgwQIOHTpUNhc0c+ZMZs+eXUl8Ro4cycMPP8yECROa1CaPiI9SqjfwPhBhdlUacLPWumlmsgRBKKN/Qis+un0Yaw6c4KPfDzBn1SHeX3GA/zu/K38Z08nT5jlSksdAbA/oegFc8qqJUbdtgckgO+Am2P4NrJxuekq2YuMK3uUCQJvo3r2vaRk9IxdRXUqFcePGkZ+fXyY8AOPGjePBBx+kqKiorEwpxQMPPNDkNnnK4eA34BGt9VLH/mjgea31GbWd5ynE4UBoSWTkFfPgZxtYvvs4Pz0whriwJl7E6ioOr4GfXoTAKDMvtONb8As2PSZbMQy6DUb+1axDyjoM+enG487Hs/fXXNb5uJpTxeEgqFR4ALTWPymlXBhPpDJKqcuBi4FQYIbW+gd3XVsQPE1EkC9PXNqTs1/5iVcX7+TFq/p42iTnaDMQbphbvn/pq+a1IBOW/QN+/w+snmmEyVpojnn7Gw+7sx4wTg1Cs8FT4rNXKfUYUJqu8UZgrzMnKqXeBS4BUrXWvSqUXwC8BliA/2mta5zZ01rPB+Y71hn9E7PWSBBOG9pFBHLjsPbM+m0/k0Z0oHOsm+d/mpKAcDj/ORjyJxORoSgbQtuYfEj7fzVlmz+HqM4Q0tqc0+kcOGOqR80+3fGU+NwGPAXMc+z/4ihzhveANzFzRgAopSzAW8C5QDKwSin1FUaIXqh6ba11quP9o47zBOG0Y+rZnflsdTIvf7+Dd26udmTk1KJVexj1f5XLel0Fox82vaLjOyHnqHFuWPSzcetuMxBOHICNc4wwDZ5UfdtCk+Mpb7cTNNC7TWu9TCmVWKV4CLDb4TWHUmoOME5r/QKml1QJZeJHvAh8q7Ve2xA7BOFUJyLIlztHd+Qf3+9g9f4MBiW20KChwdEwtsL6ooJMeHMwvHu+CQ1kKwK71RzLOWbcwP1CYchks2B2xZtw9mPGKaKBaK3dE5PPQzTEd8Ct4qOU+pqyfL8no7W+rIFNtwEOVdhPBobWUn8qMBYIU0p10lr/txpb/wT8CSAhIaGBZglC82bimYnM+m0//1q0k48nD/O0Oe4hIBxu/QZ2/QAn9pmcRkMmwweXw7KXISgaCrPN8VJnhqAYKMmHtR/AsDuNy7eT+Pv7k56eTmRkZIsUIK016enp+PvXz7HD3T2ff7r5etWitX4deL2OOtOB6WC83dxhlyC4m0Bfbyae2YGXvtvO9mPZdIsL9bRJ7iG6i9kqcus3xkMuro+ZI/p8EgREmOG45f8CbTf1lv0DMvbC+S+YBbSFWeAbbDLC7v0Z8tLMcJ9DaNq2bUtycjJpaWluvkn34e/vT9u2bet1jlvFx7G41BUcBtpV2G/rKBMEoQ4mDGnHa0t28t6v+08dzzdXENbWbAA9rzQpJTqfZwKoznKM3v/5d/jjv7BhDmQfhZA42PKF6S2d9yx88SdTzycAul1s3vr40KFDBw/cUPPGI+t8GotjzmdBqbebUsob2AmcgxGdVcD1TbVoVdb5CC2dh+dtYt7aZFY8fA4RQb6eNqf5kb4Hsg5B0mizv/Z9+MrhLdfvBtgyH0ryzH5QNKDgjp8h1BFxwlYCXt4tPohqVWpb53PKBfNUSs0GVgBdlVLJSqlJWmsrMAX4HtgGfCrREgTBeSaemUiR1c7slQc9bUrzJLJjufAADLgZ/vQT3PwVXP4fswF0GGXKivOMQ8P62bD4SXg2FmZeBFnJkFLhqyl1G8y7w9Q/zTglez7uRno+wunAjf/7g92pufzy0Bh8LKfc71LPk7LFJNMLijLhgD69udyLrip//t2kVpg32ezf9AV0PNt9trqJZhfhoAavtyxgNTBNa13ofqsE4fRm4pmJTJq1mrmrk7l+qHh41pvYnuXvu10M/7cHPr4W2g0xSfWObTLOCqlb4T9VPAtTtpRnhG3V3gRV3bcMOpxlHBlaIJ6K7fYaEE156uzxQDZGkEK11je53ahakJ6PcDpgt2sufmM5245mM7B9K+4c1ZGx3WNapHuwR/n0Ftg637y/6J9GkHJTyo8PnwLR3eCrKdD5fJN47+xHoCgXfn4JLvkX5GeYocBmTm09H0+Jzyqt9eDqypRSW7TWPWs61xOI+AinC/nFVj5ddYh3ftnH4cwCnhnXk5uGJ3rarJbFoZUw4zy4+UvTs/nhUbOQtZTYXhDTHTZViGPXZhCUFEBqhfmihw+bwKrNmOYoPtuA87XWBx37CcD3WuvuSql1Wuv+bjeqFkR8hNMNq83OVf9dQV6RlUX3nSW9H1dzeK0J/bNnqfGkQ5vFrbVx03zoOMYd1jWYZjfnA/wVWK6U2gMooAPwZ0dk61keskkQBAfeFi9uGJLAg59vZM2BEy039E5zoc0A8xoQAaveMe/Pfdq4aA+90zgw5ByBdsMgMAL+O9IETC3OM8Ny7Yd7zvYG4jFvN6WUH9DNsbujOTsZSM9HOB3JL7Yy5LklnN8zjleu7etpc04fvnMEQr17HUQkVV/n63thzUzz3jcYbl8C+cdN5IXdS+Da5vEbvjn2fAAGAokOG/oqpdBav1/7KYIguItAX28u6xfPvLXJPH5pD8ICfDxt0unBec/B4NtrFh4wEblLxac4F/5TJZRlYZbxnFv9LiSNgYgOcHwXpO82mV/jep3cppvxlKv1B0BHYD1gcxRrKqRJEATB80wYnMDHfxzkq/WHxfHAXXh51e3JFluHT1bKFhNdYcF9ENERrpgGM8aWH38yq/F2NhJP9XwGAT20rHAVhGZNrzah9GgdyuyVh7hxWHtxPGguxPWu/fjMC8vfZ+ypLDzNBE8tY94MxHno2oIgOIlSipuHt2fr0Wxue28VaTlFnjZJALPw9M5f4brZddetDqvn/46eEp8oYKtS6nul1Felm4dsEQShFsYPbsfT43ry2550Lnh1Gb/vTfe0SQKYeZuuFXo4va81URVqwqvCnN3+XyBjn+tscwJPrfMZVV25C1MuNArxdhME2JWSw6RZqwny8+bbe0Z62hyhlP2/GoeC0gja08fAkbUmUkJ4e/jWkVp8wicwe3zlc6vO/WhtEujNvQUiO8NV7zTKtGbn7dZcRUYQhJrpHBvCbWcm8uTXW9mZkkOX2BBPmyQAJJ5Zef9PS8vfF+dDQYYRIr9guPYD+LRC9LKjG6F1hRxOv78N3z9s3h9Z12jxqQ23DrsppZY7XnOUUtkVthylVLY7bREEof5c3Ccei5fiy/WSq/GUwDcQRv+tQhieKiNd00ZCQSZ893fIOw77qvQLXulmchm5ALeKj9Z6hOM1RGsdWmEL0VqfJvl7BeHUJTrEjzM7RfHl+iOIs+opSOfzYOQD8Ned5WUvd4Df34Lv/nZyCoico7DxE5eY4rGkHUopi1IqXimVULp5yhZBEJxnXN94kk8UsObACU+bItQXnwA45zEIiYVznzFl2m5eN82tPp7ckXUuMcUj4qOUmgqkAIuAbxzbAk/YIghC/Ti/Vxz+Pl58uf6Ip00RGsOZd8OQOyqX7VtWeb/7pcaLzgV4qudzD9BVa91Ta93bsfWp8yxBEDxOsJ83Y7vHsmDjEbILSzxtjtAYOtTitRjVBcZ/CH2uccmlPSU+hzCZSwVBOAW5eXgiOYVWrpv2O6k5zTYmsFAXibWIz9mPuvTSnhKfvcBPSqmHlVL3l24eskUQhHoypEME/7tlEPvT87jq7d84lJHvaZOEhuAfVvOxHuNcemlPic9BzHyPLxBSYRME4RRhdNcYPp48jKz8EqbOXofVZve0SUJ98WCsPk8tMn3KE9cVBKFp6dcunGev6M3ds9cxbdle/jKmk6dNEuqLT6BJSNftYvjjv6asywUuv6xbxUcp9arW+l6l1NectNoJtNaXudMeQRAaz2V94/l+yzFeXbyTUV2i6dWmlqEcofnxwC4TqHT5v81+q0S45j2XX9bdPZ8PHK//dPN1BUFwIc+O68XKfRmMe+tXzugYyaV94zm/Z5wkoDsVKI1+UDr/E93NrAdyMW4VH631GserxHYThBZEqyBf5t11BnNWHeTrDUd58LONPPLFJs7rEcdDF3QjITIQu90Mdnh5SU6gZkmp+FSNcuAiPJXJtDPwAtAD8C8t11rXkjdWEITmTLuIQP7v/G48cF5XNiZn8fWGI8xeeZDF21IY3TW6LCLCv67tx1ldoj1sbdPz045U2oQH0PlUD7iqLG65jKe83WYCbwNWYAwmffaHHrJFEIQmRClF33bhPHpJD5b8dTTn9ohl3cFMzugYRWSQH7fMXMmri3e2OO+4+z/dwNs/uSYIp1tIGA6BUXD2I265nKfSaAdorZcopZTW+gDwpFJqDfC4h+wRBMEFxIX58+b1A8r284utPPLFZl5dvItlO9P49/h+tI8MqnRObpGVqR+v5dpB7biwd2t3m9wgCktsZOQVk55XTWy0U4XIjvCg+8TTUz2fIqWUF7BLKTVFKXUFEFzXSYIgnNoE+nrz7/H9eO26fuxOzeXSN5bz88408oqsZDi+uGf9tp+lO9K4e846lu867mGLneNYlonycCL/FBYfN+Opns89QCBwN/AMZujtFg/ZIgiCmxnXrw0DElox+f3V3PLuSsCsd/zbBd1455e9nNkpkvTcYm6btYqJZyYy9ezOBPt5Y7XZ8bZ4LBh/jRx1iE/GKdLzueXdlXSJDeaRi3t4zAa3i49SygKM11o/AOQCE91tg8OOIOBn4EmttUTUFgQ30y4ikHl/PoMZv+zDy0uxen8GL3y7HYCHLuhGfHgAzy/cxvRle1mz/wQPX9SN22etZmTnaF6+ug/+Pu6ZGHeGY9kFAGTmnxqBVn/emcbPO9NOH/FRSnlrra1KqRGNaONd4BIgVWvdq0L5BcBrgAX4n9b6xTqaegj4tKF2CILQeAJ9vZl6TmcArDY7zy3chkLRp204YDzjzu4Ww5SP13HV2yuIDPLl641HOHQin5m3DuZfi3ay5Ug2PVqH8sSlPTzWKyrt+eQWWSmy2vDzbj7C2Fxxd89nJTAAWKeU+gqYC+SVHtRaz3OijfeANzEeckBZb+ot4FwgGVjlaN+CcemuyG1AX2ArFdy8BUHwLN4WL564tOdJ5Zf0ied4ThFz1yTz9g0D2XIkiymz13HWy0vJLrQyICGcD34/QHigD389r2ud11l38AR2DQPbt2oy20vnfACW7zpOTIg/vdtKpIfa8NScjz+QDpyNCbOjHK91io/WeplSKrFK8RBgt9Z6L4BSag4wTmv9AqaXVAml1GggCLPOqEAptVBrba9S50/AnwASEiTJqiB4klvP7MCtZ3YAICEykH9abTz02SYevbg7t49M4oG5G3hz6W56tA6t1UNOa81fPlpLWm4R7946mJGdm2a90dEK4jNp1moA9r94cZO03VJxt/jEOFInbKZcdEppTEL4NpgcQaUkA0Nrqqy1fgRAKXUrcLyq8DjqTAemAwwaNEiS1QtCM+KK/m25qHfrsuGtp8f1ZN/xPKbOXse9ablMGJJAXpGNBZuOMGFwAq2CfAHYkJzFkaxCgv28mTp7HYvvH0VUsF+DbLDZNXat8bF4cSyrkAAfCwUltrLj+cVWAn099fu++ePuT8aCcamuLr6G27/gtdbvufuagiA0DRXnVQJ9vXlv4mDumbOef/6wk9eX7MbHosgrtvHWj7uxac2QDpH4eXvh7aWYddtgrpv+O098uYU3r++PakBqgcnvr2b70Wx+e/gcjmYV0qtNKKv2nyg7vvlwNkM6RDTJvbqKYqsdX2/PzJO5W3yOaq2fdkG7h4F2FfbbOsoEQThNCPH34d1bB7MrJYcPfj9ARl4x1wxqx9cbjuDn7cX3W45xPLeYMV2jGdg+gvvO7cLL3+2g7bcBXDckgRe/3YbNrpl+06A648/lFJbw4/ZUAFKyCzmeW8QNQxNIzy1m73Ezjb3mwAmnxCcrv4TJ76/m5av7kBgVVGf9puRwZgEd3HzNUtwtPq6KKLgK6KyU6oARneuA6110LUEQmjGdY0N4elyZIyyjHHHknrqsJ1uOZNO2lYnYfNeojuxOzWXasr1MW7a3rP5L323nmkFt6RgdTHpeMcVWO63D/Fm++zj70/O5cWgCn69JLqu/cNNRAOLD/fl66gi2HMnm8S8389OOVO4a3RGtNV+uP8LwjpHEhp7s4/TD1mOs3J/Ba0t28e/x/Zr0s8gpLKGg2EZMNdcFGPPPnzw2N+Vu8TmnsQ0opWYDo4EopVQy8ITWeoZSagrwPWZo712t9ZbGXksQhJaDt8WLvu3Cy/aVUvzr2n7cPiKJDcmZdIoJ5h2HEE1btpfWYf4cyy5Ea+gZH8qWI9kAHMsq4P0VBxiQEM6mw1k89fVWAOLCAgjy82ZIhwjO6R7DW0v38NbS3UQE+fLwvE30jA/lm7tHnmSXj8M9vNja9LHuLnljOQfS8ysJTGl0cU/j7pQKGU3QxoQayhcCCxvbviAIpxc94kPpER8KwKD2rTiQns+Kven8sOUYl/WLJyrIj+cWbiur/9bSPfhavPjnNX2Zv+4wr/+4G4A24eU5cK4f2p6l29P4x/c7ysq2HMlm+7FsusWFVrp+TqFZmFpktdHUHEjPB4yXX+m8lrWK+NjsGosH0lw0vzgVgiAIHkIpRWJUEBOGJDBz4hAevrA7k89Kol2EEZavppxJ6zB/Hji/C0nRwdx/XldWPzqWd24eRKeY8vCUbcIDWHjPSC7pY9y+H724OxYvxVfrjwBmMeplby7nl11pZcFIC0tq7/kUltga3DvKLijP0WO1V24jt9A9+XuqIn6AgiAIdfD5nWew5Ug2fdqG8+tDZ1dySIgK9uPcHrHVnvfc5b0ZkNCKm4e35/e9Gby/4gAD27fiaFYhG5OzuGnGSvonhAOwfPdxdqbk0KWGfEC9n/yePm3D+fyuMwD4bE0y6blF3DGqI1uOZNEpJrjGyAqpOYWEBZqsslV7Pn+fv4k3JzTM468xSM9HEAShDmJC/RnTLQaoXybWsEAfbhvRwRG9oQfeFsWkWat5dP7msjrrDmYCEOBj4ZLXl/Pj9hS+2XgUrctFwmqzU2LTrDlwgl0pOQA8MHcDL3y7nQPpeVz8+vKyuafqSM0pqtBWZfH5ZuNRdqbkOn1PTYWIjyAIghtoFxHIwrtHcseoJLrEBvO/mwfx+oT+AIQH+vCPa/pQbLNz23ur+cvHa+nw8MKysD1HMssjKJz772W8sWRX2f6of/wEwMp9GeQVVT+ElppTfn5pEr8Le8WVla0+0Ojp+Hojw26CIAhuIj48gIcv7M7DF3YvK0uICMTHougZH0Z4gC93fLCavGLjfDDshSXEh/mTlltUqZ1XFu08qe3dqbn0fOJ7vr1nJN1bG6eGED9vcoqspGQX8f6K/YzuEoO3xfTcwgN9y87dfjSHL9Yls/ZAJuf1jG2ysEO1oSp27YTqGTRokF69erWnzRAE4TShoNjGsBeWkFVQOUXD5qfO5/M1yTzxVe0rSfa9cBFKKfo8+T3ZFRwKIoN8+fTO4Zzzys/cf24X/lWNiAFsf+aCJklZoZRao7UeVO0xEZ+6EfERBMHdpGQX4uftxTZHr2RUlxgu7tOa1JxChjy3hEv7xpNfZOXRS3rw7vJ9fPD7gbJzg/28Gds9hvkO77rqeO26fnSMDuaXXcd56bvtlY5d0b8NT1zao1LvqCGI+DQSER9BEJoTR7MKiAr2K1ugarXZWbI9lXatArno9V8q1VUKqvuaf/P6/lzSJ55FW1OY/P7J329KwdanLiDAt+E9oNrERxwOBEEQTjFahwWUCQ+Y6A3n94yjR3woP//faPY+f1HZsfdvG8Ke5y9ix7MXEB9WHman1Oute2vj2h1URWS0hu6Pf8ehjHyX3IP0fJxAej6CIJxqbDiUyfRle/nX+L5l63/yiqy8/N12gvy8ufuczmXzOoUltrL3zyzYyozl+8ra6dcunPl/ObNBNsiwWyMR8REE4XTiu81HufPDtQCE+Huz6cnzG9RObeIjrtaCIAhCJS7o1Zq9z1/E6z/u4rK+8S65hoiPIAiCcBJeXop7x3ZxXfsua1kQBEEQakDERxAEQXA74nDgBEqpNKB0BVcYkFVD1ZqORQHHXWBaU1Db/TSH9htyfn3OcaZuQ/7mtR1rzs8DuPaZaIq2XflMNPZ5qO346fg8tNdaVx+rR2stWz02YHp9jwGrPW13Q+6nObTfkPPrc44zdRvyNz9VnwdXPxNN0bYrn4nGPg91/N3leaiwybBb/fm6gceaK662ubHtN+T8+pzjTN2G/s1PxecBXGt3U7Ttymeisc9DbcfleaiADLu5AaXUal2Dr7tw+iHPg1CR0/V5kJ6Pe5juaQOEZoU8D0JFTsvnQXo+giAIgtuRno8gCILgdkR8BEEQBLcj4iMIgiC4HREfQRAEwe2I+LgZpVSQUmqWUuodpdQNnrZH8DxKqSSl1Ayl1GeetkXwPEqpyx3fD58opc7ztD2uQsSnCVBKvauUSlVKba5SfoFSaodSardS6m+O4iuBz7TWk4HL3G6s4Bbq80xorfdqrSd5xlLBHdTzeZjv+H64ExjvCXvdgYhP0/AecEHFAqWUBXgLuBDoAUxQSvUA2gKHHNVsbrRRcC/v4fwzIbR83qP+z8OjjuMtEhGfJkBrvQzIqFI8BNjt+FVbDMwBxgHJGAEC+fxbLPV8JoQWTn2eB2V4CfhWa73W3ba6C/nycx1tKO/hgBGdNsA84Cql1NucurGehIZR7TOhlIpUSv0X6K+UetgzpgkeoKbviKnAWOBqpdSdnjDMHUgmUzejtc4DJnraDqH5oLVOx4zvCwJa69eB1z1th6uRno/rOAy0q7Df1lEmnL7IMyFU5LR+HkR8XMcqoLNSqoNSyhe4DvjKwzYJnkWeCaEip/XzIOLTBCilZgMrgK5KqWSl1CSttRWYAnwPbAM+1Vpv8aSdgvuQZ0KoiDwPJyNRrQVBEAS3Iw4HThAVFaUTExM9bYYgCMIpxZo1a45rraOrOybi4wSJiYmsXr3a02YIgiCcUiilDtR0TOZ8BEEQBLcj4iMIgiCA1mArcdvlRHwEQRCaCzt/gOwjNR/XGj68Gr59CDIPwltD4ch62PY1FGbV/3qbPoN1H0JWMix5Gp6JgpJCc2zVDEh23XSDzPk0kJKSEpKTkyksLPS0KS7D39+ftm3b4uPj42lTBOHUJ+swKAWh8dUfL8yCj68Bix88mmLqlqI1FOVA9mHYvchsdiukbYdZl0JRNviFQeIIGHYn+ARB24GmJ7NhNvS9HizesGU+zL0F7loBgRHweTXB1F/pApe+Bt/cb/aTRsPNXzb1pyHi01CSk5MJCQkhMTERVfEhaSForUlPTyc5OZkOHTp42hxBcC2/vQHHd8FlNUS1sdvAy2Le56RAYCSsmWm+/C9+BXYthpTNMOJeyNgH2g6tOsCix6DHOGjdD17tZcofOgAB4eXtKi8jNMmrTJmtyIhMmCP+cEkBvHs+HN1Q2aZV/zOvRdmO1yzY8Y3ZADqNhX2/mPZ+fc3s//Ffc2zDbPALrf5eC7Ng7q3l++2G1v35NQARnwZSWFjYYoUHQClFZGQkaWlpnjZFEBpGXroRiDPuBm/fmuuVFMCyf5gv3R6XQeJI8PKGjL1GADZ/Dt/8FUY9CIXZ8OurEN0d0raZ80f9DT66yrzvMx6mjzJtDZ4Mq96BFW/CwFuN8AC81B7Oe86U/We4uWavK+GTm8ttWj0T+l0PkR3h05srC09kZ/ANgqPra7//3YvL36fvNlspv1UQ2bjecGyTeT/uLdi+sFzALn0dBt5S+3UaiCwydYJBgwbpqq7W27Zto3v37h6yyH2cLvcpNIKjGyGyE/gGOld/1yLITYX+DUjkW5gFviHgVWW6Om0n/PQ8nP8ChLY2Zb+9CT88Alf+D/pcY4TDN6i8B2MtMsNSO76FebebdkNiITcNOp0DW+ZBSGvIOeq8fb2vgU1zqz82+Pby3kpVIjsZcehyAez8rry8y4Ww89vKdc99Bopz4eeXystC28B5z8Jn9YxZfOlrRgT3/wq7foBznzJ/m392Nsf/ugNC4urXZgWUUmu01oOqOyY9H0FojhTlwB/TIO84WAvMJLC1AKK7wcgHav8lXx9sVvjtNTix37Qd3RUSzqgsJFobO4KrWSt4dCNMO8v0Csb8vfKxghOm3fj+5WV2Oyy4H3KPQefzqm+zlIO/w87v4ZzHzbDUif3w9plmCOuK/4JfMOQcM5/VF3dCxh6I6gpjHFkpDv1hXtfMhIgO8MGV0LoPXP+pub/5d5leTUwPaJVovojfvxzQRnjACE9ABJTkg9Uxv+sfDmc9AL+/bYbHKrJpLlh84b6tYCs277OTwT8MIpJML+Pre8rrB8eZzyJ9t7Hh6pnw3xHmXqBceCZ+a5wMjm2ELucbsWozCBLPhIJMCGtj6u34FjZ9Co8dB2WBhQ+YMr9gSN8Dt30Hn90GWY5MDj0c6aQSzzQbQHAMPJlVeajRBZzWPR+lVBLwCBCmtb66pnrNuefz3HPP8fHHH2OxWPDy8mLatGkMHDiQxx9/nLlz5xIUFATANddcwyOPPAKAxWKhd+/elJSU4O3tzc0338x9992HV9VfkzSf+zytsNvhkxtgx0IzieztBz7+ZiI6fRe0HQLXzqp54tpZCk6YL6I9P5ov1MJMUx7Tw0wwB8eYL6Av7oAtX8DkH6F138ptfHSN+cUc0xP+/FvlYwvuh3UfwAO7yuc49v4M7zuyx5/9KJz1f5XP+e0NOLwGRv4V3h8H+enw59+NMH48Hvb/YsTQWlD5PC9vCG9vhrbuXmfKXulqekrWQvDygaAoyE0xvZMrpsFT4eXnj/8Iul8CGz81onLEkcPt6nfNXMm2BbBymvnbxPc1w1Naww+PmmE1gJu+ML26XldB22p/7Jejtfn8/cPhu4dg5XS45FUYNBGKcuHru40wApz7NJx5jzknPwOCImtu11psPhv/sNqvn30EDq819+xCPNbzUUrdA0wGFPCO1vrVKsf9gWWAn8OWz7TWTzTieu8ClwCpWuteFcovAF4DLMD/tNYvAmit9wKTlFKfNfSanmTFihUsWLCAtWvX4ufnx/HjxykuLubRRx/l2LFjbNq0CX9/f3JycnjllVfKzgsICGD9+vUApKamcv3115Odnc1TTz3loTtpptjtcGwDxPU9eZjHlfz4jBGeC/8BQ/9U+diWL2D+X2DaKLjmvfJfq/UlbSfMvs646172Bgy42fRu9i2DL/8CMy+Cm+fDkmfKf80veRpu/Ly8jQMrjPBEdoLULaZn0irRHNPa/OK2FRtx63WlKV/3oflijO0Fq96FM+8zXlilrJoBJ/aZ+/QxP5zY/o1pe9f3Zq6k01jj7YUyQ0J+IWZyP3kVfPlnmHO9Kc9NgTGPwpF1Zu5k2J/Nl/zyf0H3S03bbQZCx7PLv4T7XGtE7N3zICgGel5pel39bzBbSWF5b0ApOP85GPOIsS1pjGnLGZQy3mYA5zxhRKi0F+IXbH5ogBl2Gz61/JzahAdMj9iZXnFofON/vDQWrbVLNqAXsBkIxAjLYqBTlToKCHa89wH+AIZVqRMDhFQp61TDNc8CBgCbK5RZgD1AEuALbAB6VDnvs9ruZeDAgboqW7duPanM3Xz++ef6kksuqVSWl5enIyIidHZ2do3nBQUFVdrfs2ePjoiI0Ha7/aS6zeE+PYLNpvVX92j9RKjWH16tdX6Ge6674VNzza/u1rqav4fWWuuUrVq/PkDrJ1tp/esbWltLqq+Xvlfr9D0nlyev1vqFdlq/3FHrAytOPr7/V62fa6P1M7HGlp9f1nr5a+b93mWmjt2u9YwLtP5HZ62PbjLHVvynvI0j603ZE6Faz7vDlBVkav1MjNZf36f1tm/Msc3zys/JSSmv/85Yrbd+pfX0MVpPG6X1f84w92wtrvmzK8jS+vm2Wj8dVX7tI+sr18nP0Pr5duXHj20+uZ3ifK2fitD6w2tqvparyTqs9ZdTjC2nMMBqXcP3qit7Pt2BP7TW+QBKqZ+BK4GXSys4jMt17Po4tqrjgKOAO5VSF2mti5RSkx3tXFj1glrrZUqpxCrFZXnSHXbMAcYBW+u6AaXUpcClnTp1qrXeU19vYeuR7Lqaqxc94kN54tKetdY577zzePrpp+nSpQtjx45l/PjxtGrVioSEBEJCQpy+VlJSEjabjdTUVGJjYxtr+qmP3Q7f3Adr3jO/PHcvhulj4LqPILb2v0mjOLwGvpoC7c80vZ6aPCljupshsC/uMhPqq/4HI++HPteZX70Ze+Gnl8zYP8rMx4z8K1h84OAf8OFV5lf3LV9Dq/Ynt9/+DNPr+fRmGDjRDI2VFBg33cVPwK0LjcfXwd/gon9CXC8zLLb9Gxh2l2lj5/fm2h3OMkNRdrvpQVkLof+NZvguIsncw4kDMHwKHFppzh10G7QbYt6n7TA9QTBDZZZa1pz5h8LUNeATaIYKD/5uhgMrEtDK9Fa+mmL2o6sZUvYJMJP6cb1OPuYuQuNNj7QF48qxhM3ASEd++kDgIipn7QNAKWVRSq0HUoFFWus/Kh7XWs/F5Lv4RCl1A3AbcE097KgpTzoO2/4L9FdKPVz1RK3111rrP4WF1TF+6iGCg4NZs2YN06dPJzo6mvHjx/PTTz9VqjNz5kz69etHu3btOHToUPUNCeXY7bDgHiM8I+6HCbNh4kLz5fu/sWZFuCvIPgqzrzfzLNe+X/fQiX+YEcPxjmGsr6bC6/3NHM6bg2HrlzD8L9D7avjpBZhxLqz/GD64wlxj4rfVC08pbQfBfVtglGNOxicARv/NCOSrvU2b3S+DAQ433K4XwYHfzDwGGI+tNgOh/02Qfxz2LjWC2GaQcUDwssCt3xivssVPGKeHQ3+Y4b2K80rdHMNhrTpArxqnZcsJjjHDVte+D1NXVx7SK2XATWY4bswjNQ+nDv+zEU7BddTUJWqKDZgErMHM67wNvFpL3XBgKdCrhuNzgGwguo5rJlJ52O1qzDxP6f5NwJv1uY/mOuxWlblz5+qxY8dWO+zWs2dPvW/fPq21DLvViM2m9fy/mOGYxU9XHvbKPqb1jPPNse/+XvNQV0MoLtB62mitn21thrDqi92u9c5FWv/vXK2fitT6mwe0zj5afnzzF1q/2N7Y/uaQysfqg7VE67dHaP3GIK13La587OBK0/6GT8qHz356Weu8dK2fDNf6xUStnwjT+vDak9v98GqtX0rS+r8jzXBb1Xtb8Fdzf8IpBx4adkNrPQOYAaCUeh7T66ipbqZSailwAabXVIZSaiRmDukL4AlM9j9nabF50nfs2IGXlxedOxuf/PXr19O1a1f69+/PlClTmDZtGv7+/thsNoqLi6ttIy0tjTvvvJMpU6a02AWzTmG3m97D+g/hLIfbcMXPIyQWbv7KDHOteNMs+rvmPeNB1Vi+/7vxrhr/UcOGepSCzmNNL0Lrk3/N97wcEoaZyf4Bt9Tu3lwbFm+YvNT0WpRCa13+zLQZCMGxsOhxMywIxiU4MMJ45x363Sy6rOh2XcqZ98J7F5ke0vAq/9pKwcX/bJi9HmTb0WwSI4MI8LWQnlvEqv0ZdI0L5daZK3nu8t6M6Gyem0qfYQ3Y7BqLV8v736xTfBzzHt9oXbo813mUUjFa61SlVAJmnmZYlePRQIlDeAKAc4GXqtTpD0zHeLHtAz5SSj2rtX7USTPK8qRjROc64Pr63ktzJDc3l6lTp5KZmYm3tzedOnVi+vTphIWF8dhjj9GrVy9CQkIICAjglltuIT7eeLcUFBTQr1+/Mlfrm266ifvvv9/Dd+NB7DaH8HxkVquPOWkE1uDtCxf9A+IHwIJ7jcfZte+bGFoNZcsXsHqGWYXfWLdXpWqeJwqJM2tTGovFG6vNzj++385XG44w50/DaB8ZZATvynfMyvl9yyCio1nTAmalfn66ca2ujvZnQNvBkLyKualtWPHJep69oheBvtV/PWmtsWsa/IXszBd+RSp++Wut+XbzMZbtTOPBC7oREWSGR4utdvKLrazaf4K/fb6R9DzzY++mYe35dc9x9qbllbX3l4/XMiAhnKU70rB4KUZ1ieaSPq25ckDbSjY+s2AbablFfLf5KNcMascz43qxJy2Xq9/+jRB/H5Y+MBofiyIlu4i4MP9K5wLsT8/Hx6Jo2+rkxb92u+a1Jbt4bckurh+aQFpOEW/fMIASm2bhpqPkF1uJDw8gISKQDlFBeFuafoamznU+SqkPgeHA58C7WuvtTjeu1C9AJFAC3K+1XuIoXwjcDkQBszAeaV6YHOZPV2njTCBba73Jse8D3Kq1fqea680GRjvaTQGe0FrPUEpdBLzquM67WuvnnL0HaN7rfFxNi79Pu824Fm+YDaMfNvMaznBkPXxyk1lA2P9GGP338pX1zpKxzyzQjO5q5mBqm0xvJhzPLWLqx+tYsTcdH4tiSIcIPpw0tPKXeXEe2G1k2PzZcSwHAB+LolWQL/FhAQT4nrxw0bp7KemfTuX87EfJJIS+7cJ579bBtAoqn/uy2zVfrDvMtGV7yCuyMeu2wXSKKXesKSi28f6K/RRZ7fRPCGd4UiTFNnuZiCWfyOf2Was5nlvMnaOSOLdHLHvScuneOpRXF+3iQEYefx7dicTIIMICzN/ihhm/s+1oDuf3jCWn0MrWI9llwvLM5b24aVh77HbNjTP+4Lc96TV+bhOGJLBiz3H2p+dXe7xbXAjvTRxCeKAP320+xr2frD+pTlSwH8dziyqVjewcxS+7jvPDfWfhpeDv8zazcn8GvdqEsvmwcYJ64crejO4azdSP1+Fj8eJIVgG5hday+6iL+8Z24Z6xnZ2qW5Xa1vk4tchUKRUKTAAmYrzRZgKztdY5DbLoFEPEp4Xep90G8/8MG+cY8Rj9UP3Oz88wMcFWvmMWOQ7/i1kM6F9DwMaKWIvNWpKMvXDHL7VP/nuYA+l5fL4mmRV701l/KBMvpXj+it7kl9h4bP5m/nlNX4Z2iODvX2ziYEY+HaKCyC+ysfpABvYqXy8hft7ce24XWgX68PzC7YT4ezNpRAdmrzzIliPZPHhBVzpFBzNl9jr6tQvn5av68OBnG7F4KWx2zcr9GXRvHUpaThFWu53L+7Uhr8jK3uN5JJ/IJyW7/MvZS5kvq3O6xXD1wLY8/fVWcous9GoTxm970vH38aKwpHxAp+KXe8/4UM7rEce/F+/kygFtWLYzjWA/bwYlRjA8KZKXvtvO4A4RXNy7NdOX7WX9oUwA2kUE8OSlPWkdFkBUiC8jX1rKxb1b86/x/QDTQ3p+4TYGtm9F99YhrN5/grlrkllz4ES1n/2QDhHEhfrz9cYjtAkPICk6mOSMfPYez6tUr1tcCGk5RdUKSlJ0UKWeV1W6xYWw/Vj5V3nbVgEknyhfxJsUHcSPfx1d4/m10WjxcTQSiZmsvxfYBnQCXtdat2x/QER8WuR9FuebVeSb5hrPp1KvroaQsQ9+fBY2f2aiHY96yLgo1+ax9t3f4fe3jLda6YLHZsaulBzeWrqbrzaY/DK924YzLCmCK/u3pWtcCHa75tppK9iZkoPW5ov+rC5RHEjPRyk4u2sMgztE4O3lRbHNTkZeEV+sO8KynSZYbd924RQUW9mZkktUsB/PjOvJhb1N7/HL9Ye5Z856fCwKfx8LMSF+pOcV87cLujF+cDsOpOfz2JebWbU/gwAfC93iQgnyszB5ZBJ92oazaFsK245mY7dr5q5JJiOvmKhgX96/bSidY4OZNGs1aTlF3H9uF45lF9I9LoTebcOYv+4wW49kM2vFAZSCszpHM+u2ISd9NvfMWceX683nkhQVxMQRHTivRyzBft4E+ZUPFx5MzycuzB9f75qHrT74/QCPzS+f5r5xWAJBft6c2z2WQYlmIWqx1V6pjQ9/P8Cj8zef1NaMWwaRGBXErpQc8opspOYU8dJ3ZrBKKRjRKYqRnaPwUgpvL8XYHrG0bRVIbpGVzPzik4boDmcWEB3sV6v9tdEo8VFKXYbp8XQC3gdmOeZxAoGtWuvEBll1CiHi08Luc98y+Opus5L+nMfNGpim4PBaM+G+/xfjGjzsLpNfJbp7ZSeA7QthzgQYcgdc9HLN7XmQ+esO88DcDfh6e3HD0AQmj0wiJtT/pHq7UnK45I3l9GoTxqvj+9EuovbgolprlmxLJaughCv6t0EDq/Zn0C0uhPDAymL970U7+WxNMtNvHkjP+LBq52psdo0CvGqZ/8kpLOHT1cmc0y2GxKigMjuAaud+tDbzIWk5Rdw1umO1cyaLtqbw9y82MfXsTtwwtH2jHAKWbk9l4nurOKtLNP++ti+RwX5OnZdXZOX5hdvoFBNMt7hQsgqKuaBX5aHf/GIr05ftJdDXwoQhCYT4u3dot7HiMwuYobVeVs2xc0rncVoyIj4t5D4LMo04rJ3lCCT5OiSNatpraG0WpS5+0uR3ARM6JWEYJAw3i1Q/v90Ms01aZOK2NTPeXb6PpxdsZXhSJG/dMKBsUr0mMvOLCfH3cYlHVn2dA05FCkts/GvRTv50VhJRTgrPqUJjY7s9CZTFFHd4pcVqrfefDsIjtBC2LTA5WfJS4YypZo7H2RQA9UEp6HyuiT+WecDEPzv4m3ktDZXvG2KiF3tQeA5nFtAq0Ockj7J/L9rJa0t2cUHPOF69rh/+PnVHNa7aY2lKWrrwAPj7WPj7RS3kB149cEZ85gJnVNi3OcoGu8QiQQATwHHb1yZYZFxvk00xqnPNrsQ1kZMC3/6fWfEf28tELGgzwDU2V6DQascSmoBPv0ToN8EU5qaakC9hbU2gy1pIzS5k1or9dIkNYUy3GEKbcLjkQHoeF7z6C4lRQcyePLRMPD5ZdZDXluzimoFtefGqPi1ybYnQfHBGfLy11mUuFFrrYqWU637qCPWiupQKQ4cOxWq10rp1ayZNmsSLL75YVn/06NHs3buXAwcOlP2qvPzyy1m8eDG5ubk1XcZ9pO00w2LrP4aCDBNuxeZ4/AJamQWL7Rxbm4EmOVh1aG3W7Xz/iAmNc/ZjxhPNDe7MGXnFXP32b3hbFB/dPozoEEcPJzjGZK2sgyOZBVz/zu9lbrk+FsXwjlGc1yOWi3q3rnMYrDbsds1DnxvvsT2pudzy7ko+uH0o245k8+j8zYzsHMULV/YW4RFcjjPik6aUukxr/RWAUmoccNy1ZrkHZ/P5NFdqSqkAsGjRIrp06cLcuXN54YUXKg1fhIeH8+uvvzJixAgyMzM5erQemRpdQWkvZ81MOPCrcVvudonJsNjhLOOOfOgPx7bShK8HkywrrpfpFbUbahYqhieY8PsL7oW9P5l5lsveML2merD/eB4/bk9lV2oOk0Yk0Skm2Knziqw27vhgNcmZBViU4rrpK5g9eVi1k/XVcSgjnwnv/E5Wfgmf3TkcpRQ/bDnG91uO8ej8zbz5426+v++ssnUo9eWjlQf5fW8GL13Vm8ggP+78cA03z1jJgfQ82kUE8ub1A1yyoFAQquKM+NyJiSrwJiYFwiHg5tpPKceJnD7tMF50sRhvzela69ecbb9KW9Xm83EcOymnjz7F8/kcPXqUqKgo/PzML+uoqPJQL7Nnz+aee+7h7bffZsWKFZxxRvnI6XXXXcecOXMYMWIE8+bN48orr2TLli1ut/+kXk6rRBj7JPS7wfQSSonqbLb+N5r9ghOQvLpckNZ9ZPK0gMkMWZRthOniV2DgbU7l4imy2li17wQ/bk9l6Y5U9jnWUfhavFiw8Shv3zCwLCRKTWitefCzjazaf4I3r+9PTIg/E2eu5Lrpv/Px5GGVVqFXx960XG743x/kF9v4aPJQ+rQNB2Bg+1b87cJurNibzk0zVvLsgq3845q+tbZVHckn8nlx4TZGdo7i2kHtUErx+oT+TPl4LSH+Psy4ZXCDRU0Q6kt91vkEA2itnR6bUUr1wgQEHQIUA98Bd2qtd1eo0xporbVeq5QKwQQivVxrvbVCnRigoOKiVqVUp4rtOMrOwqRoeF9XTiZnAXZiwvckY0LuTCi9hlLqs9p6PnV6u337Nzi2ydmPxTniesOFL9ZaJTc3lxEjRpCfn1+WUmHUqFEUFhaSlJTEnj17+OCDD9i0aRNvvGGWY40ePZqXXnqJyZMns27dOi688EKmT59Or169qh12a3Jvt1p7OaMalrTNZjXJzA6tNGLk5QNnP2LmVmpAa82RrEJ+2ZnGj9tT+XX3cfKKbfh6ezE8KZKzu8UwpmsMXl4w6b3V7E7L5cnLenLTsJoXg5ZO1v/f+V35yxiThmP1/gxunbmKyGBfZk8eRnx4QLXn7krJ4fr//YHdrvnw9qF0b139QtWXv9vOf37aw3sTBzO6a0y1dWq635vfXcnaAyf4/r6zKrkPr9yXQViAD13jnE/DIQjO0OhMpkqpi4GegH/p8E3VMDg14ExOn6M4vOm01jlKqW2YlAcV8+04ldNHV5/PBxqY08fZfD6eojSlwi+//MLSpUsZP348L774IsHBwYwZM4aAgACuuuoqnnnmGV599VUsFuO5ZLFYGDFiBHPmzKGgoIDExETXG5u206Qp2PCx6bnU1MtpCBZvE4a/dV8YMrnSocISGwfS89mTlsvetFz2pOWVveYWWQGID/Pn8v5tOLtbDMM7Rp7kAfb5n8/g7tnreGz+Zvak5vLoxd1PGpr6Yl0yry3ZxdUD2/Ln0eXOBIMSI3h/0hBumbGS8Y4huNIvfptds+7gCZZsT2XOyoP4WLz45I5hlULGVOXuczrzw9YU/j5vE9/fd1aldRtHMgtYe/AEF/dufZKX2MJNx/hl13GeHtfzpHUrQzpE1PUJC0KT40xg0f9ispGOAf6HSVGw0sn2NwPPOaIjFGBy+qyuqbJDOPpjMpqWobWe6wgM+olSai4mp8+5TtoA1ef0Geqw6zkc+Xy01i9Uue7XwNeDBg2q/I1WlTp6KK7EYrEwevRoRo8eTe/evZk1axa+vr4sX768TFTS09P58ccfOffc8o/suuuu44orruDJJ590nXElhbDtKyM6Dejl5BVZ+WVXGkVWOza7xmbX2LXGatfYHfs2bSbRrY5jNrsmM7+Evcdz2ZuWx6ET+VTs3MeH+ZMUHcyVA9rQMTqYYUmRdIkNrtWlN9jPm3duHsTzC7cxY/k+9h3P443r+5d5oP2xN50HP9vI8KRInr+i90ltDUhoxQe3D+WmGX8wftrv3HNOZ37bc5yfdqaRmV+Ct5diaFIEz17emw5RNThQOPD3sfDy1X24+u3feOHb7Tx/RW+01sxff5jHv9xCTqGVwmvsXD2wvNdX4ggE2jU2hBuGNt8wPsLphTM9nzO01n2UUhu11k8ppV4BvnWmca31NqXUS8APQB6wHuOqfRKOYb3PgXu11ielBdVav+zosbwNdKzP8F8t9qVj5rROSapLqRAdHc2CBQs4dOhQ2VzQzJkzmT17diXxGTlyJA8//DATJkxwjXFpO0zGzKxDDerlbD6cxZSP19YYiLE2AnwsdIgKom+7cK7o34aOMcEkRQWRFB1UY6TkurB4KR67pAcdo4N5/MvNXP32b8y4ZTBWu+aOD9fQLiKQ/944sMYwJP3ahfPx7cO4ccYfPPj5RiKCfDm7Wwxnd4thZOfoes21DEhoxaQRHXjnl32c2TGKbzYdYeGmYwxq3wqrXfP011s4q3NUmZPDnFWH2J+ez7u3DhIvNqHZ4Mx/YqHjNV8pFQ+kA06H73Ump48jUvXnwEda63nVtSM5fU6mupQK48aNIz8/v0x4AMaNG8eDDz5IUVF50EWlFA880AQh9qvjyDr44ErT07nhc+h4ttNzOVpr3vttPy8s3E5EkC8zbx1MQmQgFqWweJVvpbGpvErLVMVjrluceP3QBBIjA7nzwzWMe+tXgv288VKKmbcOJiywdgHp3TaMRfedxdGsQnq1CWuUEPz1vK4s3pbKXz5ei49F8eAFXbnjrI4cSM/jwtd+4dH5m5l200Dyi228tngXQzpEMKYec0SC4HJqyjJXugGPYbKMXgUcw8zPPF3XeRXOj3G8JgDbgfAqxxXG2622LKf9McFMO2JSL8wGnq2hbiIVMpk6yryBvUAHwBfYAPR09h5OlUymrqDe97lvudbPtdH6X720Pr67Xqdm5BbpSe+t1O0fWqAnvbdSZ+QW1e/abmRPao4e/Y+luvMjC/Xq/ekesWH9wRN68qxVevPhzErlb/+0W7d/aIH+esNh/drinbr9Qwv0mgMZHrFROL2hoZlMlVJewBKtdSbwuVJqAeCvtc6qh7597phbKQH+4mirYk6fJEy07E1KqfWOc/6utV5YoY1A4Fqt9R7HuTcDt1Zjb1k+H6VUMo58Plprq1JqCvA95Tl9POBb3MLZ+QN8epNZa3PTfAhr4/SpK/dlcM+cdRzPLeLxS3ow8czEZh1aJSk6mAVTR5CRV1xnME1X0bddONNvPtmR6PYRHVi46SiPf7mFYqud83vGMiChlQcsFISaqVV8tNZ2pdRbmJ4HWusioKi2c6ppY2QN5Rc53h7B9H5qa+PXKvslwEnJ5LTWNU5gOMRsYU3HhUay6TP44g4TOPPGeU6nl7bZNf9Zupt/L95JQkQg8+46k95tw1xsbNMQVCV8fnPB2+LFy1f34dI3lmOza/7v/G6eNkkQTsKZ/5wlSqmrgHmObpTgQLfwiLtO/7lXz4QF95l0yBNmg79z4pGSXci9c9azYm864/rF8+zlvdwe8r2l0i0ulFeu7UduodXp6AyC4E6cEZ87gPsBq1KqENNL0VprJ9I1tlz8/f1JT08nMjKyRQqQ1pr09HT8/esIC7P8VVj8BHQ+D659H3yqX0RZlaU7Unng0w3kF9t4+eo+XDOwbYv8HD3JZX3jPW2CINRIneKjtZZlz9XQtm1bkpOTSUtL87QpLsPf35+2bWuIEqA1LHkalv8Lel0Fl/+39sydDoqtdv75ww6mL9tLt7gQ3ry+f62LKgVBaJk4s8j0rOrKdTXJ5U4nfHx86NChg6fN8Ax2Oyx8AFbPMOmiL34FvOrO+3IwPZ+pc9ax4VAmNw5L4NGLeziVL0YQhJaHM8NuFZPb+2NC1awBznaJRULzxlYC8++CTXNNioKxTzmVY+ebjUf52+cbQcF/bhjARb2dXiomCEILxJlht0sr7juiUL/qKoOEZkxJAcydCDu/hXOegJH313lKYYmNp77eyuyVB+mfEM7r1/X3mGuyIAjNh4b4iSZjAoae8pzq+XzcSlEOzJ4A+5ebYbbBt9dYVWtNTpGVvWl5PPTZRnak5HDnqI789bwu+EiuGEEQcG7O5w1Mnh0w0QX6AWudabyuXD6OOjXm4KkvNbVVXS4fAH2K5/NxB1prck+k4DvnWnzTNrN12D/Y7nUBJ37ZS0ZeMSfySziRV0xGfjGZ+cVk5JWQmV+M1W4emcggX2bdNoRRXaI9fCeCIDQnnOn5VIxCbQVmV130WR2OXD6TqZDLRym1QFfJwQO8B7yJCbFTXTtO5fKpqS1HLp+3qJDLRyn1la6QL+h0pNhqZ2dKDrtSc0jPLa5RSPzyjzHT+3naq1RuL7mXJT/FY6ITmWCbrQJ9aRXoQ6sgX5KighnY3odWgb5EBPnSKtCXUV2jiQr2q90YQRBOO5wRn8+AQq21DcyXuVIqUDty9NRCnbl8oNYcPKU4lcunlrYalMvHUbdZ5/NxlvxiK9uOZrPlSDZbDmez+UgWO1NyKLGVLyItFZKIIB/CA42QjI1L40/7nyPQmsmKIdO5of2ZTHEIS3igL6H+3rI2RxCEBuFUhANgLCZDKEAAJkXCGTWeYahXLp+a0C7K5QPQZPl8mhFZ+SVsOZLF5iNZbDmSzebDWew9nleW0yYiyJee8aFMGpFEz/hQurcOITrE/2QhSdkKH9wDXkVw2wJGtRnomRsSBKFF4oz4+OsKuXO01rlKqTrdlXQ9cvk40VaT5/JxtHvK5vPRWpOaU2SE5nB22evhzIKyOvFh/vSID+PSvvH0jA+jZ3worcP86+6tJK+BD68Eb3+Y+C3EtAj/EkEQmhHOiE+eUmqA1notgFJqIKYnUyfaiVw+znC65/LRWnMwI7+sJ7PliBlCO55bHuM1KSqI/gnh3DS8PT3jQ+kZH0ZEUN0RB05i788w53oTGPSm+RBxmi6kFQTBpTgjPvcCc5VSpdGn44DxzjSulIrRWqcqpRIw8zTD6mugUqo/MB3jxbYP+Egp9azW+lEnm1gFdHYM3R0GrgOur68d7sJqs7MnLa9Sj2br0WxyCq0AeHspOseGMLprNL3iQ+nZJozurUMJboroytu/Met4IpLgpi8gVBaCCoLgGpxZZLpKKdUN6Ooo2uFIaeAMteby0VofqSkHT4U2nMrl4zhWbVvNNZdPYYmNHcdyTI/GMUez/Wg2RVY7AP4+XnRvHcq4fmbYrFd8GJ1jg10TkmbDJyZyQXw/uOEzCIxo+msIgiA4UHWFzVdK/QWT3jrTsd8KmKC1/o/rzWseDBo0SK9eXW9fiUrkFJaw1TFcZrYsdqXmYnOshwnx96aXY16mVxvz2iEqCG93LMpc+Y6J1ZY40qRE8JNAn4IgNB6l1Bqt9ckZD3FOfNZrrftVKVunte7fdCY2b2KSeuirn/mgQecWWzW7U3PYn17umR4d4meGzCqITdtWAe5zW7bboTgHCrNgwxxY+hx0vQiungk+daRQEARBcJLaxMeZiQKLUkqVJpJzLNpswEz2qUthiY1dKQ1zsPNSiu6tQ7l6YNsysYkJbeQXvM0KRdlGPEq3qvtlWzXlRdmUB60Ael8Ll/8HLJLITRAE9+CM+HyHWWMzzbF/h6PstKFLbAiL7h/VdA1aiyuIRWb1AlGjoGSbXktd+IWZjKL+oeY1vB3493KUhYGfozykNXQ8G7wk5pogCO7DGfF5CCM4dzn2FwH/c5lFzZGMPfDhVQ07V9uhKLeymJTUERxCeVUWCP8w44HmH15ZUKpupfX9QpzKryMIguApnPF2s2MWd77tenOaKTYrFJxo4MkK/IKN23KZQIRXIx4VBMU32KkcOYIgCKcqzkS17gy8APTAJJMDQGud5EK7mhfRXWHyj562QhAEocXgzED/TEyvxwqMwUSM/tCVRrkLpVSSUmqGpFQQBEFwL86IT4DWegnGLfuA1vpJ4OKmNEIpdY9SarNSaotS6t5GtPOuUipVKbW5mmMXKKV2KKV2K6X+Biafj9Z6UiNMFwRBEBqAM+JTpJTyAnYppaYopa4AgpvKgCp5f/oClyilOlWpE6OUCqlSVl2eg/eAC6q5RmlOnwsxw4cTlFI9muQGBEEQhHrjjPjcgwlxczcwELgRuKUJbSjL+6O1tgKleX8qMgqYr5TyA3Dk9HmjakNa62VARjXXKMvpo7UuBkpz+giCIAgeoE7x0Vqv0lrnaq2TtdYTtdZXaa1/b0IbNgMjlVKRjlQNF1E5CjVa67mY2GyfKKVuwOT0uaYe16gup08bxzX/iyOfT9WTlFKXKqWmZ2Vl1e+OBEEQhFrx+MpCrfU2oDTvz3fUkPdHa/0yUIhxfrisKXL6aK3TtdZ3aq07Vk0k5zj+tdb6T2FhYY29lCAIglABj4sPmLw/WuuBWuuzgBPAzqp1qsnpUx9O+Zw+giAILYk6xUcpdaYzZY1BKRXjeC3N+/NxleOlOX3GAROBSKXUs/W4RFlOH6WULyanz1dNYbsgCIJQf5zp+Zw0sV9DWWP4XCm1FfiaCnl/KlCW08cRceFm4EDVRhz5fFYAXZVSyUqpSQAOR4bSnD7bgE+bS04fQRCE05EaIxwopYYDZwDRSqn7KxwKxSRlazK01iPrOP5rlf0S4J1q6k2opY2FwMKG2igIgiA0HbWF1/HFrOfxBiqusckGrnalUYIgCELLpkbx0Vr/DPyslHpPa30AwLHYNFhrne0uAwVBEISWhzNzPi8opUKVUkGYNTlblVL/52K7BEEQhBaMM+LTw9HTuRz4FugA3ORKowRBEISWjTPi46OU8sGIz1eOyX5d+ymCIAiCUDPOiM80YD8QBCxTSrXHOB0IgiAIQoNwJpPp68DrFYoOKKXGuM4kQRAEoaXjTISDWEfCtW8d+z1o2qjWHkOSyQmCIHgGZ4bd3sNEBoh37O8E7nWmcaXUfY4EcZuVUrOVUv7V1GmSRHKOtqpNJlddIjmQZHKCIAieokbxUUqVDslFaa0/BexQFqrmpKjT1ZzfBpMDaJDWuhcmKsJ1Veo0ZSI5qCaZnCSSEwRBaH7U1vNZ6XjNU0pF4vBwU0oNA5xNcOMNBDiELBA4UuV4kyWSgxqTyTU4kZzk8xEEQXANtYmPcrzej4kA3VEp9SvwPjC1roa11oeBfwIHgaNAltb6hyrVPJZIDqCuZHKSz0cQBME11ObtVjGg6BeYoJwKKALGAhtra1gp1QrTw+gAZAJzlVI3aq0/LK2jtd6mlCpNJJdHLYnklFJzMInkOjZFIjlHu+nAnU3RliAIguA8tfV8LJjAoiGYNT7ejrJAKgcarYmxwD6tdZpjYeo8TJTsSkgiOUEQhNOP2no+R7XWTzei7YPAMMdwWgFwDrC6aiWlVIzWOrVCIrlhVY6XJpK7BNgHfKSUelZr/aiTdpQlksOIznXA9Q28J0EQBKEJcGbOp0Forf8APgPWApsc15oOoJRaqJQqdd1ukkRyjnZPSiYnieQEQRCaH0rr6sO0KaUitNZVPcdOSwYNGqRXrz6p0yYIgiDUglJqjdZ6UHXHauz5iPAIgiAIrsKZCAeCIAiC0KSI+AiCIAhuR8RHEARBcDsiPoIgCILbEfERBEEQ3I6IjyAIguB2TlvxkURygiAInsOl4uNkMrk66zh5rWoTyTmOnZRMThLJCYIgeA6XiY+TyeScqeNsMrn3qJJIzlFXkskJgiA0M1w97FZXMjln6jiVTK6GRHIgyeQEQRCaHS4TH2eSyTlZxyXJ5OpKJOe4tiSTEwRBcAGuHHarmEwuHghSSt1Y3zpgkskBhZhkcpc1RTI5rXW61vpOrXVHrfULjW1PEARBcB5XDrs5k0zOqYRzkkxOEAShZVFbMrnG4kwyuTrrNIdkcmvWrDmulCrNIRQG1DQJVNOxKOB4fa7pRmq7n+bQfkPOr885ztRtyN+8tmPN+XkA1z4TTdG2K5+Jxj4PtR0/HZ+H9jUe0Vq7bAOeArYDm4EPAD9H+UIgvrY6Fdo4E+hdYd8HmFzNtWZj5o1KMPM6kyocuwiTnnsP8Egj72l6fY8Bq135ObvqfppD+w05vz7nOFO3IX/zU/V5cPUz0RRtu/KZaOzzUMffXZ6HCpsrez5orZ+gmmEyrfVFddWpcPzXKvslwDvV1JtQSxsLMYLXFHzdwGPNFVfb3Nj2G3J+fc5xpm5D/+an4vMArrW7Kdp25TPR2OehtuPyPFSgxkymQtOhlFqta8jmJ5x+yPMgVOR0fR5O2/A6bma6pw0QmhXyPAgVOS2fB+n5CIIgCG5Hej6CIAiC2xHxEQRBENyOiI8gCILgdkR83IxSKkgpNUsp9Y4jVp1wmiO5pYSKKKUud3w/fKKUOs/T9rgKEZ8moKZcQtXlEQKuBD7TWk8GLnO7sYJbqM8zoSW3VIunns/DfMf3w53AeE/Y6w5EfJqG96iSS6iWPEJtKY+ybXOjjYJ7eQ/nnwmh5fMe9X8eHnUcb5GI+DQBuvpcQjXlEUrGCBDI599iqeczIbRw6vM8KMNLwLda67XuttVdyJef66g2jxAmcvdVSqm3OXXDbQgNo8G5pYQWSU3fEVMxEf+vVkrd6QnD3IFLY7sJJ6O1zgMmetoOofmgtU7HjO8LAlrr14HXPW2Hq5Gej+uQPEJCVeSZECpyWj8PIj6uoyyPkFLKF5NH6CsP2yR4FnkmhIqc1s+DiE8ToJSaDawAuiqlkpVSk7TWVmAK8D2wDfhUa73Fk3YK7kOeCaEi8jycjAQWFQRBENyO9HwEQRAEtyPiIwiCILgdER9BEATB7Yj4CIIgCG5HxEcQBEFwOyI+giAIgtsR8RGEZoJSyqaUWl9h+1vdZznddmLVcP6C4EkktpsgNB8KtNb9PG2EILgD6fkIQjNHKbVfKfWyUmqTUmqlUqqTozxRKfWjUmqjUmqJUirBUR6rlPpCKbXBsZ3haMriyJC5RSn1g1IqwGM3JZz2iPgIQvMhoMqwW8Usllla697Am8CrjrI3gFla6z7AR5RHQn4d+Flr3RcYAJSGbOkMvKW17glkAle59G4EoRYkvI4gNBOUUrla6+BqyvcDZ2ut9yqlfIBjWutIpdRxoLXWusRRflRrHaWUSgPaaq2LKrSRCCzSWnd27D8E+Gitn3XDrQnCSUjPRxBODXQN7+tDUYX3NmTOV/AgIj6CcGowvsLrCsf73zBh+AFuAH5xvF8C3AWglLIopcLcZaQgOIv88hGE5kOAUmp9hf3vtNal7tatlFIbMb2XCY6yqcBMpdT/AWmUZ8i9B5iulJqE6eHcBRx1tfGCUB9kzkcQmjmOOZ9BWuvjnrZFEJoKGXYTBEEQ3I70fARBEAS3Iz0fQRAEwe2I+AiCIAhuR8RHEARBcDsiPoIgCILbEfERBEEQ3I6IjyAIguB2/h9MbX6aWqUdtAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}